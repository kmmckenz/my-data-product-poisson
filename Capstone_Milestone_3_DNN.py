# %% [markdown]
# # Author: Katelyn M Campbell
# # Assignment: Capstone Milestone 3- DNN
# # Class: DSC-580
# # Date: 4/23/2025

# %%
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.stats.api as sms
import scipy.stats as stats
import statistics
import numpy as np
from sklearn import linear_model
from sklearn.model_selection import train_test_split
import sklearn
import warnings
from sklearn.impute import KNNImputer
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import f1_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score, cross_validate
from sklearn.metrics import mean_squared_error, r2_score
import tensorflow as tf
import os
import math
import graphviz
from tensorflow.keras.models import Sequential
from keras.models import Sequential
from keras.layers import Dense
from tensorflow.keras.utils import plot_model
from dash import Input as DashInput
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Input as KerasInput
from scikeras.wrappers import KerasRegressor
from sklearn.pipeline import Pipeline
from sklearn.tree import plot_tree
from graphviz import Digraph
import matplotlib.image as mpimg
from dash import Dash, dcc, html, Input, Output
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
from urllib.request import urlopen
#loads necessary packages

# %% [markdown]
# # Help
# 
# ### Purpose:
# To build DNN models and generate reports.
# 
# ### How to Run:
# - Run each cell in order (previous generated information may not be captured otherwise).
# - Modify the data, model and their features as needed.
# 
# ### What You'll Get:
# - Printed and saved reports of MSE, R-squared, and cross validation results (as .txt files).
# - Printed and saved observed vs. predicted value graphs (as PNG images).
# 
# ### Functions Included:
# - pd.read_csv()
# - train_test_split()
# - Sequential(), as well as add() and compile()
# - fit()
# - predict()
# - scatter(), as well as other releavant graphing functions
# - mean_squared_error()
# - r2_score()
# - print()
# 
# Please use the `help(function_name)` in a new cell to learn more about any functions.
# 
# Additional note: The interpretation is based on the model last generated by the developer. Any newly completed iterations will change the training and testing split of the data, which may impact the results. Any modifications also would alter the results. New interpretations would be required.

# %%
def log_step(step_name):
 print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {step_name}")
#logs when each step was ran

# %%
# option to upload url data
from dash import Dash, html, dcc, Output, Input
import pandas as pd
import dash
import json

app = Dash(__name__)
server = app.server

app.layout = html.Div([
    html.H1("Load Data from URL"),
    dcc.Input(
        id='url-input',
        type='text',
        placeholder='Enter the URL to load (.csv or .json)',
        style={'width': '60%'}
    ),
    html.Button('Load', id='load-button'),
    html.Div(id='data-output')
])

@app.callback(
    Output('data-output', 'children'),
    Input('load-button', 'n_clicks'),
    dash.dependencies.State('url-input', 'value')
)
def load_data(n_clicks, url):
    if not url:
        return "Please enter a URL."

    try:
        if url.endswith('.csv'):
            df = pd.read_csv(url)
            return html.Div([
                html.P("CSV loaded successfully."),
                html.Pre(df.head().to_string())
            ])
        elif url.endswith('.json'):
            df = pd.read_json(url)
            return html.Div([
                html.P("JSON loaded successfully."),
                html.Pre(df.head().to_string())
            ])
        else:
            return "Unsupported file type. Please enter a .csv or .json URL."
    except Exception as e:
        return f"An error occurred: {str(e)}"

if __name__ == "__main__":
    app.run_server(debug=True)

# for reading URL data

# %% [markdown]
# No URL was entered, so the test results meet expectations.

# %%
log_step("Loading Data")
data_clean = pd.read_csv("data_clean.csv")
data_nomean_out = pd.read_csv("data_nomean_out.csv")
data_nomedian_out = pd.read_csv("data_nomedian_out.csv")
data_log = pd.read_csv("data_log.csv")
print("Data Loaded")
#loads data and logs time
#can replace path for different data

# %%
try:
    data = pd.read_csv("data_clean.csv")
    assert not data.empty, "Loaded dataframe is empty."
    print("Data loaded successfully and is not empty.")
except FileNotFoundError:
    print("File not found. Check the file path.")
except pd.errors.ParserError:
    print("Failed to parse the file. Check format.")
except AssertionError as ae:
    print(f"Data issue: {ae}")
except Exception as e:
    print(f"Unexpected error: {e}")
    # tests loading data

# %% [markdown]
# Data was loaded, so the test results meet expectations.

# %% [markdown]
# ## Model

# %%
log_step("Analyzing Data")
#logs time step completed

# %%
X =data_clean['COVID-19 doses (daily)']
y = data_clean['Daily new confirmed deaths due to COVID-19']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_mean =data_nomean_out['COVID-19 doses (daily, no outliers)']
y_mean = data_nomean_out['Daily new confirmed deaths due to COVID-19 (no outliers)']
X_mean_train, X_mean_test, y_mean_train, y_mean_test = train_test_split(X_mean, y_mean, test_size=0.2, random_state=42)

X_median =data_nomedian_out['COVID-19 doses (daily, no outliers)']
y_median = data_nomedian_out['Daily new confirmed deaths due to COVID-19 (no outliers)']
X_median_train, X_median_test, y_median_train, y__median_test = train_test_split(X_median, y_median, test_size=0.2, random_state=42)

X_log =data_log['COVID-19 doses (daily)']
y_log = data_log['Daily new confirmed deaths due to COVID-19']
X_log_train, X_log_test, y_log_train, y__log_test = train_test_split(X_log, y_log, test_size=0.2, random_state=42)
#trains original data, no outliers based on mean, no outliers based on median, and log data sets

# %%
try:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    total_rows = len(X)
    train_rows = len(X_train)
    test_rows = len(X_test)

    if train_rows + test_rows == total_rows:
        print("Train-test split successful. Row count is consistent.")
    else:
        print(f"Train-test split mismatch. Expected {total_rows}, got {train_rows + test_rows}.")
    if X_train.index.intersection(X_test.index).any():
        print("Overlap found between training and test data.")
    else:
        print("No overlap between train and test sets.")

except Exception as e:
    print(f"Error during train-test split validation: {e}")
# test train-test split

# %% [markdown]
# The split shows that the data is split with no overlap and meets the appropriate amount of rows, so the test results meet expectations.

# %%
X_train = X_train.values.reshape(-1, 1)
X_mean_train = X_mean_train.values.reshape(-1, 1)
X_median_train = X_median_train.values.reshape(-1, 1)
X_log_train = X_log_train.values.reshape(-1, 1)
#reshapes all X_trains (Sarahjane3102, 2022)

# %%
dnn_model = Sequential()
dnn_model.add(KerasInput(shape= (X_train.shape[1],)))
dnn_model.add(Dense(256, activation='relu'))
dnn_model.add(Dense(128, activation='relu'))
dnn_model.add(Dense(64, activation='relu'))
dnn_model.add(Dense(32, activation='relu'))
dnn_model.add(Dense(16, activation='relu'))
dnn_model.add(Dense(8, activation='relu'))
dnn_model.add(Dense(1))
dnn_model.compile(loss='mean_squared_error', optimizer='adam')
# compiles dnn model using adam as optimizer (Brownlee, 2022)

# %%
dnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))
# fits dnn model (Brownlee, 2022)

# %%
predictions_dnn_model = dnn_model.predict(X_test)
# creates predictions from dnn model (Brownlee, 2022)

# %%
dnn_mean = Sequential()
dnn_mean.add(KerasInput(shape= (X_mean_train.shape[1],)))
dnn_mean.add(Dense(256, activation='relu'))
dnn_mean.add(Dense(128, activation='relu'))
dnn_mean.add(Dense(64, activation='relu'))
dnn_mean.add(Dense(32, activation='relu'))
dnn_mean.add(Dense(16, activation='relu'))
dnn_mean.add(Dense(8, activation='relu'))
dnn_mean.add(Dense(1))
dnn_mean.compile(loss='mean_squared_error', optimizer='adam')
# compiles dnn model using adam as optimizer (no outliers based on standard deviations away) (Brownlee, 2022)

# %%
dnn_mean.fit(X_mean_train, y_mean_train, epochs=100, batch_size=32, validation_data=(X_mean_test, y_mean_test))
# fits dnn model (no outliers based on standard deviaions away) (Brownlee, 2022)

# %%
predictions_dnn_mean = dnn_mean.predict(X_mean_test)
# creates predictions from dnn model (no outliers based on standard deviations away) (Brownlee, 2022)

# %%
dnn_median = Sequential()
dnn_median.add(KerasInput(shape= (X_median_train.shape[1],)))
dnn_median.add(Dense(256, activation='relu'))
dnn_median.add(Dense(128, activation='relu'))
dnn_median.add(Dense(64, activation='relu'))
dnn_median.add(Dense(32, activation='relu'))
dnn_median.add(Dense(16, activation='relu'))
dnn_median.add(Dense(8, activation='relu'))
dnn_median.add(Dense(1))
dnn_median.compile(loss='mean_squared_error', optimizer='adam')
# compiles dnn model using adam as optimizer (no outliers based on IQR) (Brownlee, 2022)

# %%
dnn_median.fit(X_median_train, y_median_train, epochs=100, batch_size=32, validation_data=(X_median_test, y__median_test))
# fits dnn model (no outliers based on IQR) (Brownlee, 2022)

# %%
predictions_dnn_median = dnn_median.predict(X_median_test)
# creates predictions from dnn model (no outliers based on IQR) (Brownlee, 2022)

# %%
dnn_log = Sequential()
dnn_log.add(KerasInput(shape= (X_log_train.shape[1],)))
dnn_log.add(Dense(256, activation='relu'))
dnn_log.add(Dense(128, activation='relu'))
dnn_log.add(Dense(64, activation='relu'))
dnn_log.add(Dense(32, activation='relu'))
dnn_log.add(Dense(16, activation='relu'))
dnn_log.add(Dense(8, activation='relu'))
dnn_log.add(Dense(1))
dnn_log.compile(loss='mean_squared_error', optimizer='adam')
# compiles dnn model using adam as optimizer (log transformed data) (Brownlee, 2022)

# %%
dnn_log.fit(X_log_train, y_log_train, epochs=100, batch_size=32, validation_data=(X_log_test, y__log_test))
# fits dnn model (log transformed data) (Brownlee, 2022)

# %%
predictions_dnn_log = dnn_log.predict(X_log_test)
# creates predictions from dnn model (log transformed data) (Brownlee, 2022)

# %%
try:
    dnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))
    print("Model trained successfully.")
    test_predict = dnn_model.predict(X_test)
    print("Model predicted successfully.")
    if len(test_predict) == len(X_test):
        print("Prediction output shape is correct.")
    else:
        print("Prediction output shape mismatch.")
except Exception as e:
    print(f"Model training or predicting failed: {e}")
# tests model fit and predictions

# %% [markdown]
# The model did train on the data 100 epochs and was able to generate predictions, so the test results meet expectations.

# %%
log_step("Data Analyzed")
#prints that step was completed

# %% [markdown]
# Three models were chosen to compare and analyze which performed the best.
# These included the Poisson regression, Random Forest, and Deep Neural
# Networks. Overall, the ideal is to see three differing styles of approaches to
# modeling, with different levels of computational complexity. The dependent
# variable in the model is the daily new confirmed deaths due to COVID-19, and
# the independent variable is the daily new COVID-19 doses. Eighty percent of the
# data will be used to train, and twenty percent will be used as testing data. All
# data sets created, (the original observations, observations without outliers based
# on standard deviations away and interquartile range away, and log
# transformation), will be ran through the models and compared.
# 
# A Random Forest model involves averaging multiple models into one, which is an
# ensemble learning method (Fandohan et al., 2022). Deep Neural Networks, on
# the other hand, have many hidden layers that learn the data (Barron et al.,
# 2021). Both techniques were chosen due to their ability to efficiently handle
# complex data interactions and large amounts of data, with low amounts of
# assumptions. The Random Forest model was performed using the
# RandomForestRegressor() function from Scikit-learn. For the Deep Neural
# Network model, the Sequential() function from TensorFlow. The chosen optimizer
# was Adam for its adaptability, and one hundred epochs were performed. The
# same performance metrics were used as in the Poisson Regression.

# %% [markdown]
# ## Visual Tools

# %%
log_step("Visually Displaying Analyzed Data")
#logs time of step

# %%
plt.scatter(y_test, predictions_dnn_model,color='red')
plt.plot([min(y_test), max(y_test)], [min(predictions_dnn_model), max(predictions_dnn_model)], linestyle='--', color='blue', label='Perfect Prediction')
plt.title("Observed vs. Predicted")
plt.xlabel('Observed Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()
plt.savefig("dnn_observed_vs_predicted.png")
#plots and saves observed vs. predictions graph

# %%
plt.scatter(y_mean_test, predictions_dnn_mean, color='red')
plt.plot([min(y_mean_test), max(y_mean_test)], [min(predictions_dnn_mean), max(predictions_dnn_mean)], linestyle='--', color='blue', label='Perfect Prediction')
plt.title("Observed vs. Predicted (with Data's Outliers Removed throug Standard Devtions Away")
plt.xlabel('Observed Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()
plt.savefig("dnn_observed_vs_predicted_mean.png")
#plots and saves observed vs. predictions graph (outliers removed using standard deviaitons)

# %%
plt.scatter(y__median_test, predictions_dnn_median,color='red')
plt.plot([min(y__median_test), max(y__median_test)], [min(predictions_dnn_median), max(predictions_dnn_median)], linestyle='--', color='blue', label='Perfect Prediction')
plt.title("Observed vs. Predicted (with Data's Outliers Removed Through IQR)")
plt.xlabel('Observed Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()
plt.savefig("dnn_observed_vs_predicted_median.png")
#plots and saves observed vs. predictions graph (outliers removed through IQR)

# %%
plt.scatter(y__log_test, predictions_dnn_log,color='red')
plt.plot([min(y__log_test), max(y__log_test)], [min(predictions_dnn_log), max(predictions_dnn_log)], linestyle='--', color='blue', label='Perfect Prediction')
plt.title("Observed vs. Predicted (with Log Transformed Data)")
plt.xlabel('Observed Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()
plt.savefig("dnn_observed_vs_predicted_log.png")
#plots and saves observed vs. predictions graph (log transformed data)

# %%
try:
    plt.scatter(y_test, predictions_dnn_model)
    plt.savefig("plot.png")
    print("Graph generated and saved.")
except Exception as e:
    print(f"Plot failed: {e}")
# tests if plot created

# %% [markdown]
# A graph of the test data against the predictions was created, so the test results meet expectations.

# %%
log_step("Visually Displayed Analyzed Data")
#prints that step was completed

# %% [markdown]
# ## Generating Reports

# %%
log_step("Generating Reports")
#logs time of step

# %% [markdown]
# ### Original Data

# %%
mse_dnn = mean_squared_error(y_test, predictions_dnn_model)
print(f'Mean Squared Error: {mse_dnn}')
r2_dnn = r2_score(y_test, predictions_dnn_model)
print(f'R-squared: {r2_dnn}')
#generates reports on original data

# %%
with open("DNN_model_report.txt", "w") as f:
    f.write("DNN Model Performance Report\n")
    f.write("========================\n")
    f.write(f"Mean Squared Error (MSE): " +  str(mse_dnn) + "\n")
    f.write(f"R-squared (R²): " + str(r2_dnn) + "\n")
# creates pdf of results

# %% [markdown]
# ### Data with Outliers Removed through Standard Deviations Away

# %%
mse_dnn_mean = mean_squared_error(y_mean_test, predictions_dnn_mean)
print(f'Mean Squared Error: {mse_dnn_mean}')
r2_dnn_mean = r2_score(y_mean_test, predictions_dnn_mean)
print(f'R-squared: {r2_dnn_mean}')
#generates reports on data with outliers removed by standard deviations

# %%
with open("DNN_model_report_mean.txt", "w") as f:
    f.write("DNN Model Performance Report (with Outliers Removed through Standard Deviations Away\n")
    f.write("========================\n")
    f.write(f"Mean Squared Error (MSE): " + str(mse_dnn_mean) + "\n")
    f.write(f"R-squared (R²): " + str(r2_dnn_mean) + "\n")
# creates pdf of results with data outliers removed through standard deviations away

# %% [markdown]
# ### Data with Outliers Removed Through IQRs Away

# %%
mse_dnn_median = mean_squared_error(y__median_test, predictions_dnn_median)
print(f'Mean Squared Error: {mse_dnn_median}')
r2_dnn_median = r2_score(y__median_test, predictions_dnn_median)
print(f'R-squared: {r2_dnn_median}')
#generates reports on data with outlier removed by IQR

# %%
with open("DNN_model_report_median.txt", "w") as f:
    f.write("DNN Model Performance Report (with Outliers Removed through IQRs Away\n")
    f.write("========================\n")
    f.write(f"Mean Squared Error (MSE): " + str(mse_dnn_median) + "\n")
    f.write(f"R-squared (R²): " + str(r2_dnn_median) + "\n")
# creates pdf of results with data outliers removed through IQRs away

# %% [markdown]
# ### Log Transformed Data

# %%
mse_dnn_log = mean_squared_error(y__log_test, predictions_dnn_log)
print(f'Mean Squared Error: {mse_dnn_log}')
r2_dnn_log = r2_score(y__log_test, predictions_dnn_log)
print(f'R-squared: {r2_dnn_log}')
#generates reports on data with outliers transformed through logarithmic transformation

# %%
with open("DNN_model_report_log.txt", "w") as f:
    f.write("DNN Model Performance Report (with Log Transformed Data)\n")
    f.write("========================\n")
    f.write(f"Mean Squared Error (MSE): " + str(mse_dnn_log) + "\n")
    f.write(f"R-squared (R²): " + str(r2_dnn_log) + "\n")
# creates pdf of results with log transformed data

# %%
def test_model_metrics(y_test, predictions, tolerance=1e-8):
    mse_2 = mean_squared_error(y_test, predictions_dnn_model)
    r2_2 = r2_score(y_test, predictions_dnn_model)
    assert np.isclose(mse_dnn, mse_2, atol=tolerance), \
        f"MSE mismatch: expected {mse_2}, got {mse_dnn}"

    assert np.isclose(r2_dnn, r2_2, atol=tolerance), \
        f"R² mismatch: expected {r2_2}, got {r2_dnn}"
    print("Model performance metrics validated successfully.")

mse_your_model = mean_squared_error(y_test, predictions_dnn_model)
r2_your_model = r2_score(y_test, predictions_dnn_model)
test_model_metrics(y_test, predictions_dnn_model)
# tests performance metrics

# %% [markdown]
# The metrics were generated correctly, so the test results meet expectations.

# %%
log_step("Reports Generated")
#prints that step was completed 

# %% [markdown]
# ## Visually Displaying the Analytical Pipeline

# %%
log_step("Visually Displaying Pipelines")
#prints that step was initialized

# %%
plot_model(dnn_log, to_file='model_plot.png', show_shapes=True, show_layer_names=True)
#gets diagram of model

# %%
log_step("Pipelines Visually Displayed")
#prints that step was completed

# %%
log_step("Stepwise Execution Complete")
log_step("Full Pipeline Execution Complete")
#finishes logging the steps in the data

# %% [markdown]
# ## Interpreting Data

# %% [markdown]
# The Deep Neural Network models did not provide compelling evidence towards effectively learning the data. As seen in the prior models, all but the logarithmic transformed data performed poorly. The original data saw a mean squared error of 43,642,823,956,364.0 and an R-squared score of -0.06804573963836003. The observed against predicted values showed data as a horizontal line to the center of the graph. With outliers removed based on the standard deviations, the mean squared error was 12,532,594,920,075.143 and the R-squared was -0.177791944955514454. The scatterplot generated from the observed against predicted values showed values dispersed all over the graph, with the majority located at the edges. The model removing outliers through the interquartile range showed a minor improvement, with the mean squared error at 1,583,783,899,306.115 and the R-squared score at -0.21009025821012806. The graph showed the values to be even more diversly spread all throughout the area of the graph. Finally, the logarithmic data had a mean squared error of 36.59449774004095 and an R-squared of 0.1526004874329061. More data
# was centralized along the diagonal area of the graph, but it still showed great variation. Feature engineering techniques could be explored to improve the Deep Neural Network models.
# 
# Overall, the logarithmic models appear to be the best way to handle outliers in this large data set. However, across various modeling, Poisson Regression, Random Forest, and DNN models had similar results with logarithmic transformed data. Unfortunately, no models generated results strong enough to make reliable decisions upon. Given this, the next steps for this research is to implement feature engineering techniques to attempt to improve model performance. If this does not improve the results, then local data may be more appropriate when creating predictive models. The former will be performed in a new file, as well as the later if poor results are received again. Insights could potentially be gained on predicting the vaccination needs for future purposes, as well as providing information to policy makers on potential effective techniques in limiting the deaths due to the virus.

# %% [markdown]
# ## GUI Elements

# %% [markdown]
# The main GUI elements implemented were in the early graphs while exploring
# the data. As the main purpose of this product is to share results and knowledge
# on model performance for pandemic related data. These graphs included Box
# Plots for COVID-19 vaccinations and deaths, were a drop down box allowed for
# specific locations or the entirety of the world data was viewed. The box plot is
# important in outlier identification. This was also applied to histograms and line
# plots of the COVID-19 doses and related deaths. Histograms are important in
# understanding the structure of the data, while the line plot could be utilized to
# indetify potential trends in the data. If an individual was interested in just local
# information, or how this compared to another area or the entire world data, it is
# now visually available to them for visualizing outliers, data structure, and trends.
# Another visual aid provided was the COVID-19 vaccinations and deaths shown on
# a map of the world. As the daily rates did not appear to add much context,
# cumulative counts were added and applied as a drop down option for the graph.
# This allows for people to see where potential areas of high or low activity for
# vaccinations administered or deaths due to the virus. All utlizied the
# update_layout() function from plotly (Plotly, n.d.). Otherwise, the product is fairly
# straight-forward, as analysis models and their results are printed. The additions
# enhance the user experience by providing a detailed and big picture viewpoints
# of the data. This could aid in analysis by identifying any areas that appear
# significant or as potential outliers to the user.

# %% [markdown]
# ## Security

# %% [markdown]
# At this time, no security systems have been developed for the product. The data utilized is made publicly available and contains no personal identifiable information. As for the processing and modeling of the data, the purpose is for educational use, only. Testing of functions is performed to ensure all are appropriately working. If anyone were to make harmful changes to these, then they would only be preventing themselves from gaining insightful results.
# 
# If users upload data that contains personal information or develop their own product that is used for important decision making, then it is recommended that more measures are included for security. Additionally, any externally uploaded data should be fully preprocessed, as the current data was. The only exception is no implementations were performed for analyzing that the data type was appropriate for the data, as this must be examined and changed on an individual basis. All cleaning and preprocessing steps should be examined with introduction of new data, as well as analyzing the newly uploaded data for validity.
# 
# There is a risk that others could make changes to the models, and therefore, change the integrity of the model. It is recommended to all users to review the models for appropriate structure prior to implementation.

# %% [markdown]
# ## Revisions

# %% [markdown]
# New additions to the product included more references, addressing security, creating a pop-up to allow url data uploads, adding tests to each function, and a help guide at the top of each file.
# 
# Updates to the files included a more in depth exploration of potential seasonality and trends in the data, fixing code to actually use the split of the train and test data, and updating codes so no warnings or error messages were received.
# 
# Failed attempts at revisions were introducing more feature engineering techniques for Poisson Regression, Random Forest, and DNN modeling. Introducing seasonality did not show increase performance in the models. As previous research has shown more success at predicting with more localized data, it is recommended to take this approach when analyzing pandemic related data (Alroy-Preis et al., 2021; Barbeira et al., 2022).
# 
# From this information and the poor performance across all models, future goals are to attempt to rectify prior errors at improving model performance in new files. If these still return poor results, an exploration of learning data at a more local level will be the new objective to compare performance against.
# 
# For adherence to industry standards, it is imperative to have reproducibile and replicabile results (Gîrjău, Horton, & Pruim, 2023). Given this information, it is recommended to not make decisions from any of the current models. Any further implementations should focus on the logarithmic transformed data set. Additionally, the elimination of errors and warning messages follows best practices. It is also recommended to learn from the work of others. Prior work was used when devloping the models, as seen in the inserted referneces.

# %% [markdown]
# ## References

# %% [markdown]
# Alroy-Preis, S., Angulo, F. Anis, E., Brooks, N., Haas, E. J., Jodar, :., Khan, F., Levy, Y., McLaughlin, J. M., Mircus, G., Pan, K., Singer, S. R., Smaja, M., Southern, J., & Swerdlow, D. L. (2021). Impact and effectiveness of mRNA BNT162b2 vaccine against SARS-CoV-2 infections and COVID-19 cases, hospitalisations, and deaths following a nationwide vaccination campaign in Israel: an observational study using national surveillance data. Lancet, 397(10287), 1819-1829. doi: 10.1016/S0140-6736(21)00947-8 
# 
# Appel, C., Beltekian, D., Dattani, S., Gavrilov, D., Giattino, C., Hasell, J.,
# Macdonald, B., Mathieu, E., Ortiz-Ospina, E., Ritchie, H., Rodes-Guirao, L., &
# Roser, M. (2025). COVID-19 pandemic [Data set]. Our World in Data.
# https://ourworldindata.org/coronavirus
# 
# Barbeira, P. B., Bartolomeu, M. L., Castelli, J. M., Del Valle Juarez, M., Esperatti, M., Fuentes, N., Galligani, G., Giovacchini, C. M., Iummato, L. E., Laurora, M., Pennini, V., Pesce, M., Rearte, A. Rearte, R., Santoro, A., Tarragona, S., & Vizzotti, C. (2022). Effectiveness of rAd26-rAd5, ChAdOx1 nCoV-19, and BBIBP-CorV vaccines for risk of infection with SARS-CoV-2 and death due to COVID-19 in people older than 60 years in Argentina: a test-negative, case-control, and retrospective longitudinal study. Lancet, 399(10331), 1254-1264. doi: 10.1016/S0140-6736(22)00011-3 
# 
# Barron, J. A., Buenrostro-Mariscal, R., Crossa, J., Montesinos-Lopez, A.
# Montesinos-Lopez, J. C., Montesinos-Lopez, O. A., & Salazar, E. (2021).
# Application of a Poisson deep neural network model for the prediction of count
# data in genome-based prediction. The Plant Genome, 14(3).
# https://doi.org/10.1002/tpg2.20118
# 
# Brownlee, J. (2022). Your first deep learning project in Python with Keras step-by-step. *Machine Learning Mastery.* https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/
# 
# Elliott, L., Loomis, D., & Richardson, D. B. (2005). Poisson regression analysis of
# ungrouped data. Occupational and Environmental Medicine, 62, 325-329. DOI:
# 10.1136/oem.2004.017459
# 
# Fandohan, A. B., Kakaï, R. G., & Mushaglusa, C. Z. (2022). Random forest in count
# data modelling: An analysis of the influence of data features and overdispersion
# on regression performance. Journal of Probability and Statistics, 1.
# https://doi.org/10.1155/2022/2833537
# 
# GeeksforGeeks. (2025). Ranom forest regression in Python. https://www.geeksforgeeks.org/random-forest-regression-in-python/ 
# 
# Gîrjău, M., Horton, N. J., & Prium, R. (2023). Fostering better coding practices for data scientists. HDSR. https://hdsr.mitpress.mit.edu/pub/8wsiqh1c/release/4
# 
# Katla, N. (2020). Poisson regression implementation- Python. *Medium.* https://medium.com/@kn12/poisson-regression-implementation-python-28d15e95dc15
# 
# Liu, J. (2024). Navigating the financial landscape: The power and limitations of
# the ARIMA model. Highlights in Science, Engineering and Technology, 88, 747-752. https://drpress.org/ojs/index.php/HSET/article/view/19082/18645
# 
# National Cancer Institute. (2023). Cleaning data: The basics. Center for
# Biomedical Informatics and Information Technology.
# https://datascience.cancer.gov/training/learn-data-science/clean-data-basics
# 
# The Pennsylvania State University. (n.d.). 9: Poisson Regression.
# https://online.stat.psu.edu/stat504/book/export/html/782#:~:text=Interpretations,tabletop%20of%20a%20certain%20area
# 
# Plotly. (n.d.). Creating and updating figures in Python.
# https://plotly.com/python/creating-and-updating-figures/#updating-figures
# 
# Sarahjane3102. (2022). How to split the dataset With scikit-learn’s train_test_split() function *GeeksforGeeks.* https://www.geeksforgeeks.org/how-to-split-the-dataset-with-scikit-learns-train_test_split-function/


