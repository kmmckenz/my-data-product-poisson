import pandas as pd
import numpy as np
import time
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import cross_validate
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, KerasInput
from tensorflow.keras.optimizers import Adam

# # Help
# 
# ### Purpose:
# To build DNN models and generate reports.
# 
# ### How to Run:
# - Run each cell in order (previous generated information may not be captured otherwise).
# - Modify the data, model and their features as needed.
# 
# ### What You'll Get:
# - Printed and saved reports of MSE, R-squared, and cross validation results (as .txt files).
# - Printed and saved observed vs. predicted value graphs (as PNG images).
# 
# ### Functions Included:
# - pd.read_csv()
# - train_test_split()
# - Sequential(), as well as add() and compile()
# - fit()
# - predict()
# - scatter(), as well as other releavant graphing functions
# - mean_squared_error()
# - r2_score()
# - print()
# 
# Please use the `help(function_name)` in a new cell to learn more about any functions.
# 
# Additional note: The interpretation is based on the model last generated by the developer. Any newly completed iterations will change the training and testing split of the data, which may impact the results. Any modifications also would alter the results. New interpretations would be required.

# Logging function to track progress
def log_step(step_name):
    log_message = f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {step_name}"
    print(log_message)  # Print log to console
    return log_message

# Data loading function

# Function to load data from CSV or JSON URL
#def load_data(url):
#    try:
#        if url.endswith('.csv'):
#            df = pd.read_csv(url)
#            return df, "CSV loaded successfully."
#        elif url.endswith('.json'):
#            df = pd.read_json(url)
#            return df, "JSON loaded successfully."
#        else:
#            return None, "Unsupported file type. Please enter a .csv or .json URL."
#    except Exception as e:
#        return None, f"An error occurred: {str(e)}"

def load_data():
    data_folder = '/workspaces/my-data-product-poisson/Data/'  

    # Verify that the folder exists
    if not os.path.exists(data_folder):
        print(f"Data folder not found: {data_folder}")
        return None

    try:
        # Load your datasets
        data_clean = pd.read_csv(os.path.join(data_folder, 'data_clean.csv'))
        data_nomean_out = pd.read_csv(os.path.join(data_folder, 'data_nomean_out.csv'))
        data_nomedian_out = pd.read_csv(os.path.join(data_folder, 'data_nomedian_out.csv'))
        data_log = pd.read_csv(os.path.join(data_folder, 'data_log.csv'))

        # Return the loaded data
        return data_clean, data_nomean_out, data_nomedian_out, data_log

    except FileNotFoundError as e:
        print(f"Error: {e}")
        return None
    except Exception as e:
        print(f"Error loading data: {e}")
        return None

# Train-test split and DNN modeling function
def train_dnn_model(X, y, epochs=10):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Build DNN model
    model = Sequential()
    model.add(KerasInput(shape=(X_train.shape[1],)))
    model.add(Dense(256, activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(16, activation='relu'))
    model.add(Dense(8, activation='relu'))
    model.add(Dense(1))
    model.compile(loss='mean_squared_error', optimizer=Adam())

    # Train the model
    model.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_data=(X_test, y_test))
    
    # Make predictions
    predictions = model.predict(X_test)

    # Evaluate the model
    mse = mean_squared_error(y_test, predictions)
    r2 = r2_score(y_test, predictions)
    
    return model, predictions, mse, r2, X_test, y_test

# Cross-validation function for DNN
def cross_validate_model(model, X_train, y_train):
    # DNN does not use cross-validation directly via sklearn, so we could use KFold here if necessary
    # However, for DNNs, the evaluation is typically done through the training process itself
    return "Cross-validation not typically applied in DNNs in this manner"

# Visualization function
def visualize_predictions(y_test, predictions, title="Observed vs. Predicted"):
    plt.scatter(y_test, predictions, label='Predictions')
    plt.plot([min(y_test), max(y_test)], [min(predictions), max(predictions)], linestyle='--', color='red', label='Perfect Prediction')
    plt.xlabel('Observed Values')
    plt.ylabel('Predicted Values')
    plt.title(title)
    plt.legend()
    plt.show()

# Function to generate model performance report
def generate_report(mse, r2, filename="DNN_model_report.txt"):
    with open(filename, "w") as f:
        f.write("DNN Model Performance Report\n")
        f.write("========================\n")
        f.write(f"Mean Squared Error (MSE): {mse}\n")
        f.write(f"R-squared (RÂ²): {r2}\n")

# Example usage:

# Load your data
data_clean, data_nomean_out, data_nomedian_out, data_log = load_data()

# For example, let's use the 'clean' dataset
X = data_clean["COVID-19 doses (daily)"]
y = data_clean["Daily new confirmed deaths due to COVID-19"]

# Train the DNN model and evaluate
model, predictions, mse, r2, X_test, y_test = train_dnn_model(X.values.reshape(-1, 1), y)

# Print the evaluation results
print(f"DNN Model MSE: {mse:.4f}")
print(f"DNN Model R-squared: {r2:.4f}")

# Generate performance report
generate_report(mse, r2)

# Visualize predictions
visualize_predictions(y_test, predictions)

# Log the model evaluation
log_step(f"DNN Model MSE: {mse:.4f}, R-squared: {r2:.4f}")
