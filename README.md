Big Data Analysis of COVID-19 Vaccinations and COVID-19 Related DeathsBy Katelyn M. Campbell  College of Engineering and Technology  DSC-580-O500 Designing and Creating Data Products  Professor Kevin Abreu  June 25, 2025
2Capstone Project ProposalGeneral InformationProject name: Big Data Analysis of COVID-19 Vaccinations and COVID-19 Related DeathsAuthor: Katelyn M. CampbellProject organization: N/AProject manager: N/ASubmission Date: 12/11/2024 Project Overview and Project ObjectivesState the Problem The problem of this experiment is to analyze worldwide data from the World Health Organization to determine vaccine effectiveness. This project will examine the effectiveness of Poisson regression, Random Forest, and DNN models on COVID-19 vaccination and COVID-19 deaths worldwide data. This will further contribute to established research and examine what models may be the most influential for this type of data, and if an ideal model is found, it could also provide useful information to vaccination producers and consumers.BackgroundIn December of 2019, the outbreak of COVID-19 began (Chaudhari & Rasal, 2020). According to the World Health Organization (2024), with 240 countries reporting, there have been 7,075,468 total deaths attributed to the virus, with 571 deaths occurring in the week of November 3rd, 2024. The virus primarily targets the respiratory system, but can also be accompanied by exhaustion, fever, pain, and sore throat (Chaudhari & Rasal, 2020). In those affected, respiratory distress, septic shock, metabolic acidosis, issues related to blood clotting, and organ failure are the most frequent causes of death (Hatipoğlu, 2020). Individuals that are older or have pre-existing health conditions are most at risk of fatality.To combat mortalities, expanding past social distancing and masks, vaccinations underwent administration beginning in December of 2020 (Bakhshandeh et al., 2023). While protecting against severe respiratory infections, the vaccine also was developed to serve the purpose of creating global immunity. The spread of the virus has been influenced by asymptomatic carriers, and by vaccinating many, those most at risk will also be better protected. Since development, over 13 billion vaccinations have been administered around the world (World Health Organization, 2024). Given the significant impact the virus has on lives around the world, it is pertinent to identify the effectiveness of the leading prevention methods. Prior studies have been conducted utilizing local data to examine COVID-19 vaccinations and their effectiveness. In Israel, using negative binomial regression modeling, all age groups showed a decrease in infection rates, hospitalizations, and deaths as vaccination rates increased (Alroy-Preis et al., 2021). With this, it is likely that other measures, such as the lockdown, were not the cause of decreased 
3infections. Similar to this was a logistic regression performed on Argentinian data (Barbeira et al., 2022). Here, comparisons were made between the number of times the vaccination was received and the death rates in people over 60 years old. It was shown that one dose of the viral vector vaccine prevented death with 80% effectiveness, and 90% effectiveness if both doses were received. This study aims to expand upon knowledge from prior research by expanding the population to all available global data.Project ObjectivesThe overall goal of this research is to identify if a Poisson regression, Random Forest, or DNN model is an appropriate model for COVID-19 vaccination and COVID-19 related death data around the world. If so, the implied relationship between the variables will give insights on vaccination effectiveness against the virus. Steps to achieve this include:1.Perform an exploratory data analysis on COVID-19 vaccination data.2. Conduct a Poisson regression, Random Forest, and DNN model to find patterns between vaccination dose status and mortality rate.3. Predict mortality rates given vaccination status.4. Analyze model performance through observed values against predicted values graphs, mean standard error, R-squared/Pseudo R-Squared, and cross validation.5. If the model does not perform well, then look for other alternatives in models, such as feature engineering techniques or subsetting the data by region.6. Compare models to find which, if any, perform well and could potentially be utilized to make informed decisions upon.ChallengesThis research attempts to unify that of ones found in various areas of the world. Controversial results may be found, given that a larger range of regions will be considered in comparison to localized findings. Also, prior to creating a model, it is difficult to select the type of model, as the pattern of the data is not known. After evaluation, it may be found that other modeling techniques are more appropriate. Poisson Regression is limited to data that has a Poisson, (positive skewed), distribution, that the variance is not larger than the mean, and that count data is utilized (Calhoun et al., 2008). On the other hand, Random Forest and DNN models are less limiting of appropriate data sets. Computational demands may also present difficulties.Benefits and OpportunitiesBenefits of this research include providing valuable information to consumers on vaccine effectiveness and to producers on potential vaccination needs in the future. Additionally, research can be compared to prior developed models, showing potential strengths and 
4weaknesses in differing techniques. If a model is found to be more efficient than others, then it could give vaccination related research a basis to start on. Project Scope The scope of this project is to create a Poisson Regression, Random Forest, and DNN model of worldwide data that shows the relationship between COVID-19 vaccination dose and mortality rate, along with a prediction of future moralities due to COVID-19.                                                                                                         Work Breakdown StructureIDTaskDependenciesStatusEffort HoursCostStart DatePlanned CompletionEstimate to CompletionActual CompletionResourceMilestone 1: Proposal Requirements Analysis1Define ProjectN/Acompleted2N/A10/31/202411/18/202418 days11/18/2024See references2Identify ResourcesTask 1completed3N/A11/7/202411/11/20244 daysongoingongoing3Establish Project TimelineTask 1completed4N/A11/21/202411/25/20244 days11/25/2024N/A4Create Rough DraftTask 1, Task 3completed6N/A11/28/202412/2/20244 days12/4/2024See references5Finalize ProposalTask 1, Task 3, Task 4completed10N/A11/28/202412/11/2413 days12/11/2024See referencesMilestone 2: Architectural Design/Model Pipeline Design6Solidify Data SourcesMilestone 1completed4 N/A1/9/20241/15/20256 days3/19/2025See references7Clean dataTask 6completed4 N/A1/16/20251/22/20256 days3/26/2025See references8Perform initial EDATask 6, Task 7completed6 N/A1/23/20242/5/202413 days3/26/2025See references9Review model and analysis selectionTask 6, Task 7, Task 8completed10 N/A2/6/20252/19/202513 days3/19/2025See references10Complete software templateTask 6, Task7, Task 8, Task 9completed10 N/A2/20/20253/5/202513 days3/5/2025See referencesMilestone 3: Implementation11Re-examine planMilestone 2completed4 N/AN/A3/6/20253/12/20256 days3/19/2025N/A12Perform Poisson regression, Random Forest, and DNN modelingTask 11completed10 N/A3/13/20253/19/20256 days3/26/2025See references
513Create prediction modelsTask 12completed4 N/A3/20/20254/2/202513 days3/26/2025See references14Analyze performanceTask 12, Task 13completed10 N/A4/3/20254/16/202513 days4/16/2025See references15DeployTask 14completed30 N/A4/17/20254/30/202510 days4/26/2025See referencesMilestone 4: Performance Analysis and Presentation16Make RevisionsMilestone 3ongoing6 (estimated)N/A5/1/255/14/2513 days5/31/2025See references17Test ModelTask 16ongoing6 (estimated)N/A5/15/255/28/2513 days6/4/2025See references18Revise/EvaluateTask 17ongoing8 (estimated)N/A5/29/256/11/2513 days6/5/2025See references19Create PresentationTask 16, Task 17ongoing10 (estimated)N/A6/12/256/18/256 days6/25/2025See references20Submit ProjectTask 16, Task 17, Task 18ongoing4 (estimated)N/A6/19/256/25/256 days6/25/2025See references   Project Completion Project Completion Criteria1 – Poisson Regression, Random Forest, and DNN Models are created with predictions.2– Models are evaluated through predicted against observed values graphs, R-squared/Pseudo R-squared, mean squared errrors, and cross-validation.3– Other potential models that may be more accurate are explored and evaluated, including feature engineering and subset data.4- New models are compared to the originals.5- The best model is explained and selected for providing information. If no model performs well, potential explanations are offered. Assumptions and ConstraintsIDDescriptionCommentsTypeStatusDate Entered1Public domain data set existsCOVID-19 vaccination and life status contain information that must be released by healthcare professionals with PHI removed. AssumptionCompleted12/4/2024   2Large data setThere must be enough observations within the AssumptionCompleted12/4/2024
6data set to allow for proper data cleaning and training.   3Unbiased data setData set must be representative of the population, not catering to any world location or demographic.AssumptionCompleted12/4/20244Model typeThe data set must be appropriate for analysis for a Poisson regression, Random Forest, and DNN model. If it does not meet these assumptions, then data transformations must be completed, or other models may need to be considered.AssumptionCompleted12/4/20245Computational CostA large data set must be utilized for a well representative sample of the population. This could have high computational demand and could be slow in processing.ConstraintCompleted12/4/20246Models with poor performanceAll original models are not performing well. Additional techniques are necessary to see if the data is appropriate for predictive modeling.ConstraintOngoing3/13/2025   Project Controls  Risk ManagementEvent RiskRisk Probability (high, medium, low)Risk ImpactRisk MitigationContingency PlanWhat is the risk?What is the probability?What is the impact if the risk occurs?What can be done to minimize the risk?What can be done to minimize the impact of therisk?Improper data setlowThis would lead to inaccurate and/or biased results (McCausland, 2021).To combat this, it is best to find multiple data sets to compare information contained and data size.Consider compiling data from multiple, trustworthy sources, if possible. May need to adjust the proposal to the available data sets. This could include not having a multivariate form of regression due to lack of stage of vaccination received. Data set not appropriate for Multivariate Logistic Regression. Aggarwal et mediumThis would lead to inaccurate results.To combat this, it is best to perform EDA analysis and examine structure of May need to perform transformations to the data to make it 
7al., (2017), demonstrated the many limitations that exist with logistic regression modeling.data prior to creating model. Once a model is created, run model summary to ensure modeling is appropriate for the data. appropriate for the model. Otherwise, other modeling types need to be considered. World-wide data is too broad for any model to learn for accurate predictions. This occurred in Aggarwal et al., (2022), when they attempted to use data for many Asian countries.mediumThis would lead to biased results.To combat this, it is best to ensure the data set is large and well representative of the population. Have an open mind to other modeling types.If no model can learn the data well, the data set will be broken down into specific locations and go through the model again. While this does not demonstrate the goal of the project proposal, it will provide valuable insights in that global data could not be compiled with the current modeling techniques utilized. Change Control Log ID         Change Description  Priority  OriginatorDate EnteredDate Assigned  Evaluator  StatusDate of DecisionIncluded in Rev. #1Data set changed- original planned data set did not contain enough data for proper analysis. The same source, Our World in Data, was used, and two data sets were combined.LowKatelyn M Campbell3/19/20253/19/2025N/ACompleted3/19/20251
82Original model type changed- the original proposed model was a multivariate logistic regression. With the change in the data, a Poisson Regression became more appropriate. Random Forest and DNN modeling were unaffectedLowKatelyn M Campbell3/19/20253/19/2025N/ACompleted3/19/20252   Roles and ResponsibilitiesNameTeamProject RoleResponsibilityKatelyn M CampbellN/AAuthorComplete project as defined. No changes in management roles are anticipated at this time, as this project does not rely on a team. Project ScheduleProject_Schedule_ProposalPrioritization of tasks will go based on the order outlined in the project schedule, as tasks rely on the completion of those prior. Any contingencies will utilize time set towards reviewing and revisions. Necessary resources will include data from a public domain, internet service, and coding software (Microsoft Visual Studio Code, Jupyter, and Python). There is no indication of these impacting the scheduling.Cost Estimate (if applicable)Cost estimate is not applicable, as data will be sourced from public domain sources, at which no cost will be required for data access. Computational cost may apply due to the size and complexity of the project and may result in breaking the project into sections. This would include a file saved specifically for data cleaning; EDA; the model, its predictions and performance measurements; and into other model forms for comparison. If this still does not aid in reducing 
9computational cost, then it may be necessary to break the data down into regional analysis, instead of worldwide analysis.  Issue LogIssues Log ID    Issue Description       Project Impact       Action Plan/Resolution    Owner Importance Date Entered Date to Review Date Resolved1What is the issue?How will this impact scope, schedule &cost?How do you intend to deal with this issue?Who manages this issue?    2Finding appropriate data (potential)If appropriate data is not found in the given time frame, it could push back the time frame in exploratory data analysis. With this, it would postpone model creation, as it is imperative to ensure multivariate logistic regression is appropriate for the given data set. This could also impact the scope, as it may need to be adjusted towards the ideal model type to be analyzed, or if all of the variables are not available in the data set chosen. Cost will not be impacted, as data will be used from a public domain space, such as Kaggle.To deal with the issue, it is best to find a worldwide data set that is the closest to the size and the ideal variables. If the data set is lacking in some area, then a combination of data sets may be compiled, or the scope of the project may be adjusted accordingly.Katelyn M. Campbellhigh12/11/20243/19/20253/19/20253Multivariate Logistic Regression is not appropriate (potential)This will impact the scope of the project, as multivariate logistic regression was Other models will be utilized instead of logistic regression.Katelyn M. Campbellhigh12/11/20243/19/20253/19/2025
10the chosen form of modeling. If it is seen that the data does not meet model assumptions, then time will need to be set aside for identifying more appropriate models. These revisions will push back model creation, analysis, and performance. Cost will not be impacted, but the computational cost may be based on model and data complexity.4Worldwide data cannot be used to create a well-performing model (potential)This will impact the project scope, as the goal is to compile worldwide data into a singular model of vaccination effectiveness. Schedule may be impacted, as time will need to be dedicated towards attempting other models. Only computational cost will be impacted, as each model is generated.If worldwide data is unable to be utilized in a well-performing model, then the conclusion will be that worldwide data on COVID-19 vaccination and deaths is inappropriate. Data will be broken down into regions, and analysis will be performed again.Katelyn M. Campbellmedium12/11/20245/29/20256/5/2025    Overall Instructor Feedback/CommentsIntegrated Instructor Feedback into Project Documentation☐Yes ☐ NoProject Approval☐Instructor <Insert Name and Title>
11Requirements AnalysisUse CasesUse CasesSystem DesignWindows is the operating system readily available, so it will be utilized. As Microsoft Visual Studio Code and Jupyter Notebooks are familiar, they will also be utilized in the system design. Modules and subprograms included will be:•Pandas (Larose & Larose, 2019)οTo read the data •Matplotlib (Matplotlib development team, n.d.)οFor all graphical representations♣EDA histograms, box plots, bar graphs, and/or pie charts♣Observed vs. Predicted scatterplot•Numpy (Larose & Larose, 2019)οTo find any potential calculations determined necessary as project goes on•Sklearn οTo fit the Poisson Regression model (Scikit-learn developers, n.d.d)οTo fit the Random Forest model (Scikit-learn developers, n.d.a)οTo find performance metrics (Scikit-learn developers, n.d.c.)οTo perform cross-validation (Scikit-learn developers, n.d.b)•TensorFlowοTo fit the DNN model (Fchollet, 2025)οTo add layers to the DNN model (Fchollet, 2025)οTo select the optimizer for the DNN model (James77777778, 2024)System DesignTechnical RequirementsThis project will use Microsoft Visual Studio Code, with a Jupyter notebook and Python as the coding language. GitHub CodeSpaces and Repository will be used for deployment. The hardware utilized to perform this will be RAM of 16GB and an Intel Core processor, due to it being readily available. Necessary packages include:•Pandas (Larose & Larose, 2019)οTo read the data •Matplotlib (Matplotlib development team, n.d.)οFor all graphical representations♣EDA histograms, box plots, bar graphs, and/or pie charts♣Observed vs. Predicted scatterplot•Numpy (Larose & Larose, 2019)οFor any potential calculations•Sklearn οTo fit the Poisson Regression model (Scikit-learn developers, n.d.d)οTo fit the Random Forest model (Scikit-learn developers, n.d.a)οTo find performance metrics (Scikit-learn developers, n.d.c.)οTo perform cross-validation (Scikit-learn developers, n.d.b)•TensorFlowοTo fit the DNN model (Fchollet, 2025)οTo add layers to the DNN model (Fchollet, 2025)
12οTo select the optimizer for the DNN model (James77777778, 2024)System Logical Model or Data Science Model1.Importing data to be utilized for analysis.2.Perform data cleaning: this will mitigate any inaccuracies created by erroneous data.3.Perform EDA: This will provide valuable information on the structure of the data and give indications on if Poisson regression, Random Forest, and DNN models are appropriate, or if other modeling may be necessary.4.Train model: This allows for the model to learn the data to base any predictions on.5.Create model predictions: This will test if the model is able to predict given data.6.Evaluate model performance: This will provide insights into if the model was able to learn the data to make accurate predictions, or if other analysis types may need to be explored.Data PipelineReports•Pseudo-Squared and R-Squared (Scikit-learn developers, n.d.c.)οThe Pseudo R-Squared and R-Squared values are an indication of the goodness of fit of a model. A value closer to 1 is ideal.οBelow is an example of R-Squared outputs:•MSE (Scikit-learn developers, n.d.c.):οThe mean squared error, or MSE, is a measure of the average squared distance between the observed and predicted value. A lower value is more ideal.οBelow is an example of an output for MSE:
13•Predictions vs. ObservationsοThe graph will show the predicted values against the observed values. Ideally, there will be a positive correlation exhibited in the graph.οBelow is an example of the graph output (Scikit-learn developers, n.d.e):♣•Cross-ValidationοCross-validation is a technique to show the results are replicable, as well as examines if overfitting is occurring (Larose & Larose, 2019). It is ideal to have similar results, all close to 1, but not too high so that the model shows overfitting (Scikit-learn developers, n.d.b).οExample output (Scikit-learn developers, n.d.b).:♣array([0.96..., 1. , 0.96..., 0.96..., 1. ])Screen Definitions and LayoutsThe system will utilize Jupyter and Python through Microsoft Visual Studio code, with GitHub CodeSpaces as the developing website. The breakdown of the project will be on multiple folders and files, to lower computational costs. This includes one for data cleaning; EDA; individual folders for each model, with their respective predictions and performance measurements; and folders for revisions made to improve performance of models. Data cleaning will be separated into sections based on removing any missing data, mitigating the impact of outliers, ensuring data types are appropriate for their variables, and related descriptions. Exploratory data analysis will include sections based on a summary of each variable, a representative graph, and description based on the results. A discussion on if assumptions for each model will be discussed after data cleaning and EDA have been performed. Then, a dedicated file for the model built, a summary of its results, predictions and related graphs, performance metrics, and a description will be created. Finally, the creation of other files will be dependent on if other modeling should be performed and will be evaluated accordingly. The browser will show all graphs and computations generated for each model. Some screens will have drop down menus to allow for selecting specific portions of the data, or even different models.Project Layout
14SecuritySecurity is not a priority for the model. The model will be utilizing data from public domain, and therefore any privacy risks will already be factored into the data set by the data managers. There will be no personal health indicators present, and the individual will be protected by utilizing an ID notation. Users will be instructed to re-evaluate all models and data prior to running the product, to ensure standards and assumptions are met for their own work. Any prior conclusions will be noted that they were formed on a previous iteration of the models, and not the current ones. Users will be notified that new iterations require new analysis and discussion. 
15References Aggarwal, R., AlAjmi, M. F., Bajaj, M., Hassain, A., Hassan, M. I., Rustagi, V., Singh, A., Singh, I. K., Singh, P., & Tanvi. (2022). Analyzing the effect of vaccination over COVID cases and deaths in asian countries using machine learning models. Frontiers in cellular and infection microbiology, 11. doi: 10.3389/fcimb.2021.806265Aggarwal, R., Pramesh, C. S., & Ranganathan, P. (2017). Common pitfalls in statistical analysis: logistic regression. Perspectives in Clinical Research, 8(3), 148-151. doi:  10.4103/picr.PICR_87_17Alroy-Preis, S., Angulo, F. Anis, E., Brooks, N., Haas, E. J., Jodar, :., Khan, F., Levy, Y., McLaughlin, J. M., Mircus, G., Pan, K., Singer, S. R., Smaja, M., Southern, J., & Swerdlow, D. L. (2021). Impact and effectiveness of mRNA BNT162b2 vaccine against SARS-CoV-2 infections and COVID-19 cases, hospitalisations, and deaths following a nationwide vaccination campaign in Israel: an observational study using national surveillance data. Lancet, 397(10287), 1819-1829. doi: 10.1016/S0140-6736(21)00947-8Barbeira, P. B., Bartolomeu, M. L., Castelli, J. M., Del Valle Juarez, M., Esperatti, M., Fuentes, N., Galligani, G., Giovacchini, C. M., Iummato, L. E., Laurora, M., Pennini, V., Pesce, M., Rearte, A. Rearte, R., Santoro, A., Tarragona, S., & Vizzotti, C. (2022). Effectiveness of rAd26-rAd5, ChAdOx1 nCoV-19, and BBIBP-CorV vaccines for risk of infection with SARS-CoV-2 and death due to COVID-19 in people older than 60 years in Argentina: a test-negative, case-control, and retrospective longitudinal study. Lancet, 399(10331), 1254-1264. doi: 10.1016/S0140-6736(22)00011-3Bakhshandeh, B., Emameh, R. Z., Falak, R., Heshmatnia, J., Mirtaleb, M. S., Soleimanjahi, H., & Taheri, R. A. (2023). An insight overview on COVID-19 mRNA vaccines: 
16advantageous, pharmacology, mechanism of action, and prospective considerations. International Immunopharmacology, 117. https://doi.org/10.1016/j.intimp.2023.109934Calhoun, P. S., Elhai, J. D., & Ford, J. D. (2008). Statistical procedures for analyzing mental health services data. Psychiatry Research, 160(2), 129 – 136. https://doi.org/10.1016/j.psychres.2007.07.003Chaudhari, P. M., & Rasal, S. D. (2020). A review on pandemic disease COVID-19: structure, pathophysiology, epidemiology and treatment. Journal of Advanced Scientific Research, 11, 56-63.Fchollet. (2025). The sequential model. TensorFlow. https://www.tensorflow.org/guide/keras/sequential_modelHatipoğlu, N. (2020). The "new" problem of humanity: new coronavirus (2019-nCoV / COVID-19) disease. Medical Journal of Bakirkoy, 16(1), 1-8. doi: 10.5222/BMJ.2020.22931James77777778. (2024). Tf.keras.optimizers.Adam. TensorFlow. https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/AdamLarose, C. D. & Larose, D. T. (2019). Data science using Python and R. John Wiley & Sons, Inc. DOI:10.1002/9781119526865Matplotlib development team. (n.d.) Matplotlib 3.9.3 documentation. Matplotlib. https://matplotlib.org/stable/ McCausland, T. (2021). The bad data problem. Research-Technology Management, 64(1), (68-71). https://doi.org/10.1080/08956308.2021.1844540Scikit-learn developers. (n.d.a). 1.11. Ensembles: Gradient boosting, random forests, bagging, voting, stacking. Scikit-learn. https://scikit-learn.org/1.5/modules/ensemble.html
17Scikit-learn developers. (n.d.b). 3.1 Cross validation: evaluating estimator performance. Scikit-learn. https://scikit-learn.org/1.5/modules/cross_validation.htmlScikit-learn developers. (n.d.c). 3.4.4. Regression metrics. Scikit-learn. https://scikit-learn.org/1.5/modules/model_evaluation.html#regression-metricsScikit-learn developers. (n.d.d). PoissonRegressor. Scikit-learn. https://scikit-learn.org/1.5/modules/generated/sklearn.linear_
18Final Architectural Plan or Model Pipeline DesignPrepared for: Professor Kevin AbreuProject name: Big Data Analysis of COVID-19 Vaccinations and COVID-19 Related DeathsPrepared by: Katelyn M. CampbellContributors: N/ADesign Planning SummaryThis project is developed to address the accessibility of big data COVID-19 related studies. While there is widely available research on vaccination effectiveness, many of these are based on local populations. As this is a global problem and should be generalizable, this study aims to utilize a worldwide data set of COVID-19 vaccinations and COVID-19 related deaths, to determine vaccine effectiveness and make predictions on COVID-19 deaths. The virus has had a significant impact on round the world, and knowing the best prevention strategies is important to protecting the health of all people. This analysis would provide useful information to policy makers and vaccine producers about where vaccine readiness and preparation should be, as well as researchers on what techniques may work best for large pandemic data.This project hopes to establish if a Poisson regression, Random Forest, and/or DNN modeling are appropriate for predictive modeling of data on COVID-19 vaccination rates and deaths over the globe. If the model created does not perform well, other modeling methods will be utilized in comparison. An alternative model that may be explored is XGBoost. If none of the proposed models perform well, then the data will be preprocessed into groups by region, and a Poisson regression, Random Forest, and DNN will be created again to see if this produces a higher quality model. The most effective model at balancing accuracy and reliability can serve as a starting point for future pandemic-related big data analysis.Overview of Design ConceptsThe goal of this project is to use global data COVID-19 vaccination status, and reported cases influence the related deaths over time. In doing so, relevant information can be gained to provide recommendations on responses to policy makers and producers. For example, if vaccination rates are strongly correlated with low death rates, and seasonality is found in COVID-19 infection rates, vaccine producers may develop more vaccines prior to the expected outbreak. Additionally, if any of the models show high accuracy in predictions, it could provide researchers with a potential starting model when dealing with worldwide pandemic data. Accumulated data by Our World in Data from the World Health Organization will be utilized in analysis (Appel et al., 2024). Variables will include daily confirmed deaths as the dependent variable, the date and country as confounding variables, and the daily confirmed COVID-19 vaccinations as the independent variable. Before applying Poisson Regression, Random Forest, 
19and DNN modeling, missing observations, outliers, duplicated observations, and corrected data types will be addressed. The data will be split by date, with the first 80% of data will be used to train and the later 20% of the dates will be used to test the data. Metrics used to analyze model performance include graphical representations of observed against predicted values, R-squared/pseudo R-squared, mean squared error, and cross validation. Alternative models will be considered, such as XGBoost, and/or segmenting the data regionally prior to modeling. Comparisons between the differing models will be done, and the optimal model, if any are found, will be selected.Deliverable Acceptance LogIDDeliverable DescriptionComments1Import dataThis will utilize Pandas to import a CSV file from Our World in Data.2Clean and prepare dataAny missing observations and outliers will be handled as determined appropriate given the data. Duplicate observations will be removed. Data will be examined to ensure appropriate the data type is appropriate for the variable.3Perform EDAInitial statistics, such as mean, median, standard deviations, and interquartile range will be computed for variables. Appropriate graphs will accompany this, and their shapes will be analyzed. 4Train Poisson regression modelThe model will follow 80% of the data to be utilized in training and 20% for testing.5Create model predictionsModel predictions will be generated for one year past the data set. A graph of the previous data along with the predictions will be generated.6Evaluate model performanceModel performance will be analyzed using the model summary, observed against predicted values graph, accuracy, confusion matrix, ROC curve, and k-folds cross-validation.7Repeat with Random ForestA random forest model will be trained, fit, have model predictions and performance metrics created.8Repeat with DNNA DNN model will be trained, fit, and have model predictions and performance metrics created.9Try with regional dataThe above modeling steps will be performed with regional data, to see if 
20the models perform better with this over worldwide data.10ReviseAny revisions that appear necessary or other models to be explored will be performed.(For Data Science Students Only) Detailed Model Pipeline Design Data SourcesAppel, C., Beltekian, D., Dattani, S., Gavrilov, D., Giattino, C., Hasell, J., Macdonald, B., Mathieu, E., Ortiz-Ospina, E., Ritchie, H., Rodes-Guirao, L., & Roser, M. (2024). COVID-19 pandemic [Data set]. Our World in Data. https://ourworldindata.org/coronavirusas cited in Official data collated by Our World in Data (2024), World Health Organisation (2024), and Population based on various sources (2024).Data Types•Entity: string/object (the regions)•Day: date/object•Daily new confirmed deaths of COVID-19: integer•COVID-19 vaccinations administered: integerData Cleaning ProcedureMissing observations will need to be addressed prior to performing the analysis (National Cancer Institute, 2023). If possible, research from other data sources should be done to attempt to fill any gaps. This would be a direct transfer of data from the new source to fill in the missing data, granted that the surrounding data is like the data set used.  If no substitutes appear appropriate, then the observation will be removed. Any duplicates found must be removed. Outliers will be searched for using three standard deviations and interquartile ranges away. If any are found, it will be determined if standardization or removal is more appropriate. Standardization will be more appropriate if there is a wide array of outliers spread throughout the data, and removal will be used if there are few outliers. Each data type should match those listed in data types. If there is a data type coming across incorrectly, then the data will be transformed and examined to ensure effectiveness.Data Exploration and VisualizationData exploration will include getting representative counts of each region, to understand the diversity in the data set, and a bar graph will be made (Selfridge et al., 1996). This could be important in any data handling, as representation is significant. Summaries along with histograms of each region will be generated, to understand any potential differences in distribution, such as mean, median, standard deviation, interquartile range, minimum, and 
21maximum. An aggregated summary for all of the regions will also be performed, to understand the entirety of the data set. Again, this will include the mean, median, standard deviation, interquartile range, minimum, maximum, and accompanying histograms and box plots. Line graphs will be created to show the number of vaccinations and deaths related to COVID-19 over time. A scatterplot will be generated of the observed COVID-19 vaccinations and deaths, to see if there is a linear trend that exists in the data. Finally, rolling mean graphs and a differencing graph will be generated to show if there is any seasonality in the data.ModelThe initial model to be created was chosen as a Poisson regression. This was largely due to Poisson models being appropriate for count-based data and widely used. Another reason is that while ARIMA is a well-developed model, it does have its limitations (Liu, 2024). ARIMA models do not handle long-term predictions well and would not accurately capture any outlier spikes that may occur. COVID-19 began in 2020 and is still challenging for people with health concerns to this day. Having a model that could predict further out would be beneficial, as COVID-19 appears to be lingering. Additionally, any potential implementation of policy changes in regard to handling the virus is likely to be an equally strong change in the data. ARIMA modeling would struggle to provide accurate predictions as they assume a more stable occurrence in the data.The independent variables will be the daily new vaccinations of COVID-19, the cofounding variables are the date and entity, and the dependent variable is the daily new confirmed deaths due to COVID-19. The first 80% of the data will serve to train the model, while the remainder will be the testing data. A Poisson regression can be mathematically represented as log(λ i) = log(ni) + Xiβ (Elliot et al., 2005). Here, i is the entity, λ is the expected number of deaths on a given day, n is the offset term, X is the independent variables, and β is the coefficient to be estimated. With this data and model, we will gain insights on how vaccinations and time can influence the rate of deaths across varying regions of the world. Predictions will also be generated and analyzed for efficiency. Other model types will be compared to the Poisson model as appear fit to the data.Additional feature engineer techniques that may be utilized include lagged variables, interaction terms, polynomial features, and seasonal features. If autocorrelation is detected within the data, lagged dependent variables can be implemented (Keele & Kelly, 2006). By including the past values into the model, it can capture the patterns in the data, allowing for potential reduction in the autocorrelation of residuals. If there is the possibility of a multiplicative interaction of the predictors, such as the number of booster doses greatly decreasing death rates, adding interactions terms to the formula would be beneficial to interpretability and accuracy (Kruschke, 2015). Another possibility is that the data exhibits nonlinear trends. Expanding to allow for polynomial features could benefit model accuracy through better assumption of the shape of the data (Assaleh & Shanableh, 2010). A final concern is seasonality in the data. If COVID-19 is 
22more infectious during specific periods of the year, it would be imperative to address seasonality in the model’s algorithm to produce accurate predictions (Fogliatto & Porto, 2024).Random forest utilizes ensemble learning, combining multiple models through averaging techniques (Fandohan et al., 2022). It does not require linear data and therefore, can capture complex data interactions. As for neural networks, there are many hidden layers utilized to learn the data and are also not bound to the assumption of linearity (Barron et al., 2021). Given this, they are capable of identifying complex patterns in the data and are known to be efficient with large datasets. As both proposed alternative models are different in how they learn the data and work well with large, complex datasets, they are ideal comparisons to the Poisson model. Additionally, if there are available Poisson adaptations to random forest and neural networks that could improve upon initial modeling. However, with more complex modeling comes more computational demands. This could significantly impact the ease of the model, causing difficulties with replicability for future research.Analysis MethodologyAs for analysis of the model, measures of goodness of fit will include R-squared and pseudo R-squared (Scikit-learn developers, n.d.b.). With these measures, the closer to one indicates the better fit for the model.  As for the predictions, a graphical representation of the observed against predicted values will be analyzed, along with the mean squared error (Scikit-learn developers, n.d.b.). Here, the mean squared error should exhibit a lower value, while the graphs should show the data centered around a 45-degree angled line. Cross validation will be performed in order to ensure consistency of results (Scikit-learn developers, n.d.a). The comparison models will be as closely analyzed to this structure as appropriate for the model type.Configuration ChangesAt this time, one potential configuration change being explored is identifying if most regional data performs better than worldwide data, as well as researching potentially modeling with XGBoost.System SecuritySystem security is not a concern for this project. The data set utilized contains deidentified information and is listed as public domain. Therefore, any leaking of information will not impact the people involved. Additionally, this project is to serve as potential guidelines for future research. Any potential changes to the data or design will be made after conclusions have already been drawn upon the data, and the techniques will be performed in a way that is easy to reimplement. Users will be made aware of any limitations within the system, and that if it is used for any sensitive data or modeling, they must implore their own security measures.
23Hardware and Software Technologies1-CPU- Intel(R) Core (TM) i7-8550U2-RAM- 16 GB3-Hard drive- Hard disk drive 2 TB4-Motherboard- ASUS Q525 Model5-OS- Windows 116-Program- Microsoft Visual Studio Code7-Software- Juypter Notebook8-Language- Python9-GitHub Repository10- GitHub CodespaceRevision and Signoff SheetChange RecordDateEditorRevision Notes2/10/2025Katelyn M. CampbellInitial draft for review/discussion3/5/2025Katelyn M. CampbellRevisions added to include justification for Poisson Regression, more detailed explanation for handling of missing data, discussion on feature engineering techniques, comparison of model trade-offs, and addition of real-world applications5/21/2025Katelyn M CampbellRevisions to update data used and model types after performing the modeling and deployment.
24ReferencesAppel, C., Beltekian, D., Dattani, S., Gavrilov, D., Giattino, C., Hasell, J., Macdonald, B., Mathieu, E., Ortiz-Ospina, E., Ritchie, H., Rodes-Guirao, L., & Roser, M. (2024). COVID-19 pandemic [Data set]. Our World in Data. https://ourworldindata.org/coronavirusAssaleh, K., & Shanableh, T. (2010). Feature modeling using polynomial classifiers and stepwise regression. Neurocomputing, 73(10), 1752-1759. https://doi.org/10.1016/j.neucom.2009.11.045Barron, J. A., Buenrostro-Mariscal, R., Crossa, J., Montesinos-Lopez, A. Montesinos-Lopez, J. C., Montesinos-Lopez, O. A., & Salazar, E. (2021). Application of a Poisson deep neural network model for the prediction of count data in genome-based prediction. The Plant Genome, 14(3). https://doi.org/10.1002/tpg2.20118Elliott, L., Loomis, D., & Richardson, D. B. (2005). Poisson regression analysis of ungrouped data. Occupational and Environmental Medicine, 62, 325-329. DOI: 10.1136/oem.2004.017459Fandohan, A. B., Kakaï, R. G., & Mushaglusa, C. Z. (2022). Random forest in count data modelling: An analysis of the influence of data features and overdispersion on regression performance. Journal of Probability and Statistics, 1. https://doi.org/10.1155/2022/2833537Fogliatto, F. S. & Porto, B. M. (2024). Enchanced forecasting of emergency department patient arrivals using feature engineering approach and machine learning. BMC Medical Informatics and Decision Making, 24. https://doi.org/10.1186/s12911-024-02788-6Keele, L. & Kelly, N. J. (2006). Dynamic models for dynamic theories: The ins and outs of lagged dependent variables. Political Analysis, 14, 186-205. doi:10.1093/pan/mpj006
25Kruschke, J. K. (2015). Overview of the generalized linear model. Doing Bayesian data analysis: a tutorial with R, Jags, and Stan, 2, (pp. 747-759). Elsevier Inc. https://www.sciencedirect.com/book/9780124058880/doing-bayesian-data-analysis#book-infoLiu, J. (2024). Navigating the financial landscape: The power and limitations of the ARIMA model. Highlights in Science, Engineering and Technology, 88, 747-752. https://drpress.org/ojs/index.php/HSET/article/view/19082/18645National Cancer Institute. (2023). Cleaning data: The basics. Center for Biomedical Informatics and Information Technology. https://datascience.cancer.gov/training/learn-data-science/clean-data-basicsScikit-learn developers. (n.d.a). 3.1 Cross validation: evaluating estimator performance. Scikit-learn. https://scikit-learn.org/1.5/modules/cross_validation.htmlScikit-learn developers. (n.d.b). 3.4.4. Regression metrics. Scikit-learn. https://scikit-learn.org/1.5/modules/model_evaluation.html#regression-metricsSelfridge, P. G., Srivastava, D., & Wilson, Lynn O. (1996). IDEA: Interactive data exploration and analysis. ACM SIGMOD Record, 25(2), 24-34. https://doi.org/10.1145/235968.2333
26ImplementationBig Data Analysis of COVID-19 Vaccinations and COVID-19 Related DeathsSystem EntitiesEDA (script): The purpose of this entity is to understand the structure of the data, as well as having a data cleaning section. It contains a variety of functions, including initial examination of the data, with summary statistics, a variety of visualizations showing data structure, handling for any missing or duplicated data, and different techniques of outlier handling, and a save function for the cleaned data sets.Poisson Regression (model): The purpose of this entity is to create a Poisson Regression model, with predictive analytics, predictive against observed graphical representation of the data, and performance metrics (pseudo R-squared, mean squared error, and cross validation). The following diagram can also be found in the PDF files with the source code.Random Forest (model): The purpose of this entity is to create a Random Forest model, with predictive analytics, predictive against observed graphical representation of the data, and performance metrics (R-squared, mean squared error, and cross validation). The following diagram can also be found in the PDF files with the source code.
27DNN (model): The purpose of this entity is to create a Deep Neural Network model, with predictive analytics, predictive against observed graphical representation of the data, and performance metrics (R-squared and mean squared error). The following diagram can also be found in the PDF files with the source code.
28Feature Engineering (script): The purpose of this entity is to introduce feature engineering based on any data that the EDA showed seasonally or trend data, and the above models did not perform well. It also contains the same predictive against observed graphical representation of the data, and performance metrics (R-squared, mean squared error, and cross validation) as the above models.Regional Poisson Regression (model): The purpose of this entity is to replicate the work of the earlier Poisson Regression model, but with only using logarithmic transformed data from the US and Canada.Regional Random Forest (model): The purpose of this entity is to replicate the work of the earlier Random Forest model, but with only using logarithmic transformed data from the US and Canada.Regional DNN (model): The purpose of this entity is to replicate the work of the earlier DNN model, but with only using logarithmic transformed data from the US and Canada.
29Functional RequirementsEDA: (Testing results are available in the source code.)Loading datapd.read_csv(file path)Checking for missing values/Removing missing valuesdata.isnull().sum()data.isnull().dropna()Checking for duplicated values/Removing duplicated valuesdata.duplicated().sum()data.duplicated().drop_duplicates()Checking data typesprint(data.dtypes)Converting date to date-timepd.to_datetime(data['Day'])Graphing dataplt.boxplot()fig_box1 = go.Figure()fig_hist1 = go.Figure()fig_line1 = go.Figure()data_rolling7.plot()data_grouped['COVID-19 doses (daily)'].diff().plot()plt.scatter()px.choropleth()plt.hist()Outlier detectionStandard Deviations:mean_vaccine = statistics.mean(data['COVID-19 doses (daily)'])vaccine_mean_outlier_high = mean_vaccine + (std_dev_vaccine * 3)vaccine_mean_outlier_low = mean_vaccine - (std_dev_vaccine * 3)vaccine_hmean_outlier_count = np.sum(data['COVID-19 doses (daily)'] > vaccine _mean_outlier_high)vaccine_lmean_outlier_count = np.sum(data['COVID-19 doses (daily)'] < vaccine_mean_outlier_low)vaccine_mean_outlier_count = vaccine_hmean_outlier_count + vaccine_lmean_outier_count
30IQRs:statistics.median(data['COVID-19 doses (daily)'])iqr_vaccine = stats.iqr(data['COVID-19 doses (daily)'])q1_vaccine = np.quantile(data['COVID-19 doses (daily)'], 0.25)q3_vaccine = np.quantile(data['COVID-19 doses (daily)'], 0.75)vaccine_median_outlier_high = q3_vaccine + (iqr_vaccine * 1.5)vaccine_median_outlier_low = q1_vaccine - (iqr_vaccine * 1.5)vaccine_hmedian_outlier_count = np.sum(data['COVID-19 doses (daily)'] > vaccine_median_outlier_high) vaccine_lmedian_outlier_count = np.sum(data['COVID-19 doses (daily)'] < vaccine_median_outlier_low)Outlier HandlingStandard Deviations:data_nomean_out = {}data_nomean_out = pd.DataFrame(data_nomean_out) data_nomean_out['COVID-19 doses (daily, no outliers)'] = data['COVID-19 dose s (daily)'].clip(lower=vaccine_mean_outlier_low, upper=vaccine_mean_outlier_high)IQRs:
31data_nomedian_out = {}data_nomedian_out = pd.DataFrame(data_nomedian_out) data_nomedian_out['COVID-19 doses (daily, no outliers)'] = data['COVID-19 doses (daily)’].clip(lower=vaccine_median_outlier_low, upper=vaccine_median_outlier_high)Log Transform:data_log ={}data_log = pd.DataFrame(data_log)data_log['COVID-19 doses (daily)'] = np.log1p(data['COVID-19 doses (daily)'])Summary statistics of datadata.describe()Saving graphsplt.savefig()Saving cleaned datadata_log.to_csv('data_log.csv', index=False)Poisson Regression: (Model diagram can be found in the system entities, as well as in the source code. Testing results are also available in the source code. Regional Poisson Regression utilizes the same functional requirements.)Loading datapd.read_csv(file path)Splitting data into training and testing groupsX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)Initializes modellinear_model.PoissonRegressor()Fits modelclf.fit(X_train.values.reshape(-1, 1),y_train)Generates model predictionsclf.predict(X_test.values.reshape(-1, 1))Creates predicted against observed graphplt.scatter(y_test, predictions, label='Predictions')Finds pseudo R-squaredclf.score(X_test.values.reshape(-1, 1), y_test)Finds mean squared errormean_squared_error(y_test, predictions)Cross-validates findingscross_validate(clf, X_train.values.reshape(-1, 1), y_train, cv=5, 
32scoring=['neg_mean_squared_error', 'r2'], return_train_score=True)Random Forest: (Model diagram can be found in the system entities, as well as in the source code. Testing results are also available in the source code. Regional Random Forest utilizes the same functional requirements.))Loading datapd.read_csv(file path)Splitting data into training and testing groupsX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)Initializes modelRandomForestRegressor(n_estimators=10, random_state=0, oob_score=False)Fits modelregressor.fit(X_train.values.reshape(-1, 1),y_train)Generates model predictionsregressor.predict(X_test.values.reshape(-1, 1))Creates predicted against observed graphplt.scatter(y_test, predictions, label='Predictions')Finds mean squared errormean_squared_error(y_test, predictions_RF)Finds R-squaredmean_squared_error(y_test, predictions_RF)Cross validating findingscross_validate(regressor, X_train.values.reshape(-1, 1), y_train, cv=5, scoring=['neg_mean_squared_error', 'r2'], return_train_score=True)DNN: (Model diagram can be found in the system entities, as well as in the source code. Testing results are also available in the source code. Regional DNN utilizes the same functional requirements.))Loading datapd.read_csv(file path)Splits data into training and testing groupsX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)Initializes modelSequential()Adds input layerdnn_model.add(KerasInput(shape= (X_train.shape[1],)))Adds layer to modeldnn_model.add(Dense(256, activation='relu'))
33Compiles modeldnn_model.compile(loss='mean_squared_error', optimizer='adam')Fits modeldnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))Generates model predictionsdnn_model.predict(X_test)Graphs observed against predicted valuesplt.scatter(y_test, predictions_dnn_model, color= 'red')Finds mean squared errormean_squared_error(y_test, predictions_dnn_model)Finds R-squared valuer2_score(y_test, predictions_dnn_model)Feature Engineering: (No diagrams or testing was created for this section, as it followed structures of all past developed models.)Loading datapd.read_csv(file path)Converts date object to datetime objectpd.to_datetime(data['Day'])Log transforms datanp.log1p(data['COVID-19 doses (daily)'])Sorts data by entity and timedata.sort_values(by=['Entity', 'Day'])data.groupby('Entity').cumcount()Drops missing valuesdata.isnull().dropna()Drops duplicated valuesdata.duplicated().drop_duplicates()Checks data typesprint(data.dtypes) Adds columns to data frame for seasonalitynp.sin(2 * np.pi * data['day_of_year'] / 365)np.cos(2 * np.pi * data['day_of_year'] / 365)Splitting data into training and testing groups-Poisson Regression-Random Forest/DNNsplit_date = data['Day'].quantile(0.8) train_data = data[data['Day'] <= split_date] test_data = data[data['Day'] > split_date]X_train, X_test = X.iloc[:-int(len(X)*0.2)], X.iloc[-int(len(X)*0.2):]y_train, y_test = y.iloc[:-int(len(y)*0.2)], y.iloc[-int(len(y)*0.2):]Poisson Regression:-Initialization/Fit-predictionssmf.glm( formula='COVID_deaths_daily ~ COVID_doses_daily + time_index + sin_year + cos_year', data=train_data, family=sm.families.Poisson() ).fit()poisson.predict(test_data)Random Forest:-Initialization-Fit-PredictionsRandomForestRegressor(n_estimators=100, random_state=42)rf.fit(X_train, y_train)
34rf.predict(X_test)DNN:-Initialization-Adds input layer-Adds layer-Compiles-Fits model-Predictions Sequential()dnn.add(KerasInput(shape= (X_train.shape[1],)))dnn.add(Dense(256, activation='relu'))dnn.compile(loss='mean_squared_error', optimizer='adam')dnn.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))dnn.predict(X_test)Graphs observed against predicted valuesplt.scatter(test_data['COVID_deaths_daily'], predictions_poisson, color='blue')Poisson Performance Metrics-Pseudo R-squared-Mean squared error-Cross validationprint (poisson.summary())mean_squared_error(test_data['COVID_deaths_daily'], predictions_poisson)KFold(n_splits=5, shuffle=True, random_state=42) pseudo_r2_scores = [] (followed by model structure)Random Forest Performance Metrics-R-squared-Mean squared error-Cross validationr2_score(y_test, predictions_rf)mean_squared_error(y_test, predictions_rf)cross_validate(rf, X_train, y_train, cv=5, scoring=['neg_mean_squared_error', 'r2'], return_train_score=True)DNN Performance Metrics-R-squared-Mean squared errorr2_score(y_test, predictions_dnn)mean_squared_error(y_test, predictions_dnn)
35Source Code ListingThis is uploaded as PDF files with comments and markdowns explaining each block of code.
36Code Review The code was periodically reviewed by fellow classmates and the professor overseeing the capstone project, and their revisions were implemented in the code and its markdowns.
37Implementation PlanOverall, this project is attempting to learn pandemic-related big data and make accurate predictions based on it. Data cleaning and exploration, modeling through Poisson regression, Random Forest, and DNN, analysis of performance metrics, and further exploration of feature engineering techniques were implemented. The purpose of this is to identify potential successful techniques at analyzing worldwide pandemic related data together, instead of at a more localized analysis level. This could be utilized as a basis for other future research on similar topics. However, localized data was implemented to serve as an additional comparison tool.For this project, Microsoft VS Code was used, with Python as the language and Jupyter Notebook as additional software. The data utilized was “daily-covid-19-vaccine-doses-administered" and “daily-new-confirmed-covid-19-deaths-per-million-people were utilized” merged together from Our World in Data (Appel et al., 2025).Reference:Appel, C., Beltekian, D., Dattani, S., Gavrilov, D., Giattino, C., Hasell, J., Macdonald, B., Mathieu, E., Ortiz-Ospina, E., Ritchie, H., Rodes-Guirao, L., & Roser, M. (2025). COVID-19 pandemic [Data set]. Our World in Data. https://ourworldindata.org/coronavirusThe following libraries were installed:•Loading/saving dataοimport pandas as pdοfrom urllib.request import urlopen•Graphing dataοimport matplotlib.pyplot as pltοimport seaborn as snsοimport math import graphvizοfrom sklearn.tree import plot_tree  οfrom graphviz import Digraph οimport matplotlib.image as mpimgοimport plotly.express as px οimport plotly.graph_objects as go οfrom plotly.subplots  import make_subplotsοfrom tensorflow.keras.utils import plot_model•Modelingοimport statsmodels.api as smοimport statsmodels.stats.api as smsοimport statsmodels.formula.api as smf
38οimport sklearnοfrom sklearn import linear_modelοfrom sklearn.model_selection import train_test_splitοfrom sklearn.impute import KNNImputer οfrom sklearn.preprocessing import StandardScalerοfrom sklearn.ensemble import RandomForestRegressorοimport tensorflow as tfοfrom tensorflow.keras.models import Sequential οfrom keras.models import Sequential οfrom keras.layers import Dense οfrom tensorflow.keras.layers import Dense οfrom tensorflow.keras.layers import Input as KerasInput οfrom dash import Dash, dcc, html, Input, Outputοfrom sklearn.pipeline import Pipeline•Performance Metricsοfrom sklearn.metrics import f1_scoreοfrom sklearn.model_selection import cross_val_score, cross_validateοfrom sklearn.metrics import mean_squared_error, r2_scoreοfrom sklearn.model_selection import KFold•Other:οimport scipy.stats as statsοimport statisticsοimport numpy as npοimport warningsοimport osοimport timeStrategy for integration included initial development on a local Jupyter notebook environment, to later be developed on a Git repository. The repository will have the folders for EDA, Poisson Regression, Random Forest, DNN, and Feature Engineering, to match the modular breakdown of the scripts. Any updates to the product will be implemented on the Git repository.Processing of data went through the following steps:•EDAοThe structure of the data was viewed.οThe data was cleaned of any missing or duplicated values, and outliers were handled. Data types were also explored for appropriateness with the given data.οGraphical representations of the data’s structure were generated.οCleaned data was saved for future use.
39•Poisson Regression (for both worldwide and local data)οData was split into training and testing groups.οThe model was initialized and then fit.οModel predictions were generated.οA graph of the predicted values against original values were generated.οThe performance metrics Pseudo R-squared, mean squared error, and cross validation were computed.οAll performance metrics were saved to a file.οAnalysis showed that logarithmically transformed data had the best results, but none were strong enough to use for making informed decisions upon.•Random Forest (for both worldwide and local data)οData was split into training and testing groups.οThe model was initialized and then fit.οModel predictions were generated.οA graph of the predicted values against original values were generated.οThe performance metrics R-squared, mean squared error, and cross validation were computed.οAll performance metrics were saved to a file.οAnalysis showed that logarithmically transformed data had the best results, but none were strong enough to use for making informed decisions upon.•DNN (for both worldwide and local data)οData was split into training and testing groups.οThe model was initialized and then fit.οModel predictions were generated.οA graph of the predicted values against original values were generated.οThe performance metrics R-squared and mean squared error.οAll performance metrics were saved to a file.οAnalysis showed that logarithmically transformed data had the best results, but none were strong enough to use for making informed decisions upon.•Feature EngineeringοData was cleaned, preprocessed, and logarithmically transformed.♣The data now included a section that allows for seasonality to be included in the model structure.οData was split into training and testing groups.οPoisson Regression, Random Forest, and DNN models were initialized and then fit.οPredictions were generated for each model.
40οGraphs of the predicted values against original values were generated for each model.οThe performance metrics for Poisson Regression included:♣Pseudo R-squared, mean squared error, and cross validationοThe performance metrics for Random Forest included:♣R-squared, mean squared error, and cross validationοThe performance metrics for DNN included:♣R-squared and mean squared errorοAll performance metrics were saved to a file.οAnalysis showed that including seasonality as a feature engineering technique did not have a strong impact on each model’s performance metrics. It is recommended that future research on similar data should analyze the data in more local forms, in order to have better success at creating quality models.For users, an option to upload new data through a URL is available. Interactive graphs in the exploratory data analysis will allow for selection of different countries or different structures of the data. PDF files and PNG images of the outputs, reports, and generated graphs will be available for transparency to users. Additionally, a User Guide is to follow this section.Potential risks involving users include uploading inappropriate, inconsistent, or inaccurate data could lead to poor model performance. Additionally, any newly uploaded data must be integrated into the remainder of the analysis, whether through merging or replacement of the current data. Otherwise, the data will not be included with the current structure of the product. If any data with personal identifiers is uploaded, encryption must be included to protect those at risk. The current data set did not include any identifiable information, so encryption techniques were not accounted for. Security measures to protect the integrity of the model were also not implemented, as the product is for informational purposes only. This leads to the risk of improper modification of the model, which could lead to misleading results. It is imperative that any users using the models as a basis for their own projects verify the structure of the model prior to implementation. One final risk is making misinformed decisions based on the models. The worldwide data models are highly limited and have consistently shown poor performance metrics and replicability. At this stage in the analysis, it is recommended to attempt to use logarithmic transformed data, as that consistently lowered the mean squared error, and regional data with a Random Forest model. Given the data used, it showed the strongest performance, with the United States data reporting a mean squared error of 0.1980 and R-squared of 0.8176. Canadian data was also used and found to have a strong performance, with a mean squared error of 0.1828 and R-squared value of 0.8372. One drawback was that this still may not provide consistent results, as it did receive a poor average R-squared value from cross validation. Poisson Regression and DNN models did not show the same success with the regional data. However, it is important to note that each data set is different, and differing results may be found. It is imperative to thoroughly explore each data set for its qualities and examine the performance 
41under a new model iteration, as well as to ensure consistent results through cross validation. While the worldwide data models were not successful, a better understanding of how worldwide health related data should begin analysis process was found, and future researchers have a recommended starting point for their individual research. This should save researchers valuable time and allow for more efficiency in their own developing code. More detailed findings can be seen in the source code.
42Big Data Analysis of COVID-19 Vaccinations and COVID-19 Related Deaths: A User GuideBy Katelyn M. Campbell
43User Guide:Big Data Analysis of COVID-19 Vaccinations and COVID-19 Related DeathsKatelyn M. CampbellCollege of Engineering and TechnologyDSC-580-O500 Designing and Creating Data ProductsProfessor Kevin AbreuMay 28, 2025
44Copyright © 2025 by Katelyn M. Campbell All rights reserved. No portion of this book may be reproduced in any form without written permission from the publisher or author, except as permitted by U.S. copyright law.
45
46PrefaceThis document is a user guide that accompanies the data product, Big Data Analysis of COVID-19 Vaccinations and COVID-19 Related Deaths. Its intended purpose is to serve as a guideline for worldwide health related data research, specifically pandemic related research. The audience for this product is other fellow researchers to gain insights on best handling data with similar structure. By reviewing this product, they can identify the most appropriate and efficient methods for their own research. Within the product, there is exploratory data analysis with data cleaning, Poisson Regression modeling, Random Forest modeling, Deep Neural Network modeling, and feature engineering. While a logarithmic regression was found to be most efficient at minimizing the mean squared error, none of the worldwide data models, even with feature engineering, showed promise of replicable results or large R-squared values. Due to this limitation, it is recommended of future researchers to localize their data sets, giving a more centralized focus on data for models to learn on. Large, worldwide data sets are hard to create reliable models upon and often exhibit poor performance. To save time and gain efficiency, the localized data will be easier and quicker to implement for researchers. Specifically, the Random Forest model showed the best overall performance with this data set. However, there were conflicting results with R-squared scores in cross validation, so current models are still not trustworthy to draw conclusions upon. This is just a potential starting model for similar data. Additionally, each data set is unique, there are many different modeling systems available, and future techniques or research could be identified that are capable of handling big data.
47Table of Contents•General information49•System summary51•Getting started52•Using the system53•Troubleshooting70•FAQ71•Help and contact details 72•Glossary73Note: Please use Ctrl + F to search this document as needed
48General InformationThis user guide contains five sections: EDA (Exploratory Data Analysis), Poisson Regression, Random Forest, Deep Neural Network, and Feature Engineering. All regional sections of analysis follow similar structures to the original models, with a focus on logarithmic transformed data, as it was found to be the best at lowering mean squared error metrics across all models. The intended users of this product are researchers attempting to model similar data sets. This is version 1, released on April 23rd, 2025.EDA (Exploratory Data Analysis): Within the Exploratory Data Analysis, the product explores the data through descriptive statistics, a variety of graphical representations of the data, and data cleaning procedures.Poisson Regression: In this section, the previously cleaned data is split it into training and testing groups. Initiation and fitting of a Poisson Regression model is performed. Predictions are made from this, with a scatterplot of the observed and predicted values plotted against one another. Performance metrics, such as pseudo R-squared, mean squared error, and cross validation are computed. A discussion of the interpretation of results (based on the last run model), user interface, security, and revisions are included. Any new iterations will present a mismatch between the current interpretation. All references utilized within the work are included.Random Forest: In this section, the previously cleaned data is split it into training and testing groups. Initiation and fitting of a Random Forest model is performed. Predictions are made from this, with a scatterplot of the observed and predicted values plotted against one another. Performance metrics, such as R-squared, mean squared error, and cross validation are computed. A discussion of the interpretation of results (based on the last run model), user interface, security, and revisions are included. Any new iterations will present a mismatch between the current interpretation. All references utilized within the work are included.DNN (Deep Neural Network): In this section, the previously cleaned data is split it into training and testing groups. Initiation and fitting of a DNN model is performed. Predictions are made from this, with a scatterplot of the observed and predicted values plotted against one another. Performance metrics, such as R-squared and mean squared error are computed. A discussion of the interpretation of results (based on the last run model), user interface, security, and revisions 
49are included. Any new iterations will present a mismatch between the current interpretation. All references utilized within the work are included.Feature Engineering: Initial iterations of the model did not show ideal results for R-squared values, graphs of observed against predicted values, or cross validation results. It was identified in the EDA that there could be seasonality or trends present in the data. Therefore, feature engineering that included seasonality within the Poisson Regression, Random Forest, and DNN models, was implemented. Matching graphs and performance metrics for each were computed. Interpretations were made, but any new interations will modify the results. User interface, security, revisions, and references are included.
50System SummaryThe main features of the system are data input, descriptive statistics, data cleaning visualizations, modeling, predictions, and performance metrics. The system is broken into five different components: Exploratory Data Analysis (including data input, descriptive statistics, visualizations, data cleaning, and saved data files), Poisson Regression (including data input, modeling, predictions, visualizations, and saved results), Random Forest (including data input, modeling, predictions, visualizations, and saved results),  Deep Neural Network (including data input, modeling, predictions, visualizations, and saved results), and Feature Engineering (including data input, data cleaning, modeling, predictions, visualizations, and saved results).Technologies used are Microsoft VS Code, Jupyter Notebook, Python, Pandas, Matplotlib, Seaborn, Scikit-Learn, TensorFlow, Keras, SciPy, NumPy, Statsmodels, Statistics, Os, Math, Graphiz, Dash, Time, URLLib, and Plotly. Exact libraries can be found in the beginning of the source code. Python version 3.12 was used. All libraries are required for complete functionality of code.Inputs were taken from Our World in Data, specifically their csv files “daily-covid-19-vaccine-doses-administered" and “daily-new-confirmed-covid-19-deaths-per-million-people were utilized” were merged together (Appel et al., 2025). There is an option for uploading data through URL, but the escape key can be used to bypass this. If any new data were used for input, there will likely be a need to be changes made to how the data is called to ensure accurate referencing to areas of the data frame.Reference: Appel, C., Beltekian, D., Dattani, S., Gavrilov, D., Giattino, C., Hasell, J., Macdonald, B., Mathieu, E., Ortiz-Ospina, E., Ritchie, H., Rodes-Guirao, L., & Roser, M. (2025). COVID-19 pandemic [Data set]. Our World in Data.Outputs include saved cleaned data, any graphs, and performance metrics generated throughout the product.
51Getting Started1)Installation: To begin, first install any programs or applications not previously owned. Follow the instructions provided by the developers that are appropriate for your operating system. Once installed, install any libraries that are not already downloaded into your environment using pip install.2)Clone GitHub repository: Into your environment, copy the GitHub repository and upload data or copy any code desired.3)Revisions: If desired, make any appropriate revisions in your environment. This could be uploading your own data set and making appropriate adjustments or adding any new functionalities.4)Running: Run all cells as your first iteration, in sequential order.5)Revisions: If any errors or warnings are found, update with the appropriate revisions. If no changes were made the program should run completely through on the first iteration.6)Running: After any corrections or adjustments are made, run your second iteration.7)Interpretation: Examine all results and draw conclusions from them.
52Using the SystemExploratory Data Analysis (EDA):1.After the appropriate system applications are installed, install and load all of the packages. The ones used throughout the project include:  2.Load the data. There is a URL option, which will include a pop-up to upload data through. If this is not desired, hit the escape button. Doing this will product the message “Unsupported file format or no url entered.” If using Pandas to read a csv file that is not the originally noted data, replace with the path to your file. Depending on the structure of the data, names of the columns may need to be adjusted. (Note, this data set did require 
53the merging of two data sets to hold all the wanted information.) 3.As for performing data cleaning and preprocessing, outlier handling, missing value removal, and duplicated value removal are included. There are four different techniques in outlier handling included, keeping outliers, removing outliers through three standard deviations away, removing outliers through one and half interquartile ranges away, and logarithmic transformation. It is likely one technique is more appropriate for the data set chosen than others. 
54All could be run to use as comparisons with modeling, or turning the undesired ones into comments using the ‘#’ symbol at the beginning of the line could be done. Additionally, the data types are shown. 
55If any do not appear appropriate for their given column, apply techniques to change the values within the column to the appropriate type. For example, this data needed the date to be in a date time format. 4.For data exploration, a print out of summary statistics and a wide variety of graphs are included. Any graphs can be tailored to different needs. Currently, there are many different countries included in the data set, so they are the primary focus of interactions available for users. A filter system was included to show whatever the user wanted to focus on. 
56
57Additionally, visualizations and descriptions of the data after outlier handling had been implemented were included.5.Data was saved into different files after cleaning. These files are to be uploaded in the other modules of the product. Poisson Regression:1.Downloading the required libraries is the same as shown in the EDA module (page 24).2.Uploading the data is also the same as shown in the EDA module (pages 24-25).3.Splitting data into training and testing groups is important for capturing the ability of the model to accurately generate predictions. The model was split into eighty percent of the data into training, and twenty percent of the data into training. This was done for each different outlier handling data sets created. 
584.The Poisson Regression model was initialized through the following code (for each different outlier handling data sets created): 5.It was then fit through running (for each different outlier handling data sets created) 6.Then, the predictions were generated by running (for each different outlier handling data sets created): 7.Scatterplots of the observed against predicted values were generated, (for each different outlier handling data sets created), to show visualizations of how well the model is predicting the data. The more data that is situated around the line of best fit, the better the model is performing. 
59A copy of one of the generated graphs is shown below: 8.The next step is generating the performance metrics of the models. The mean squared error was found using: A lower score for this metric is ideal.The Pseudo R-squared value was found using: A score closer to 1 or –1 is ideal for this metric.Cross validation was performed through: Values should mimic those initially computed to indicate replicability of the model.
609.All performance metrics are saved into a PDF file when the following code is run: 10.Interpretations should be completed based on the results found.11.If desired, a diagram of the model’s structure can be visualized by running the following code: Random Forest:1.Downloading the required libraries is the same as shown in the EDA module (page 24).2.Uploading the data is also the same as shown in the EDA module (pages 24-25).3.Splitting data into training and testing groups is important for capturing the ability of the model to accurately generate predictions. The model was split into eighty percent of the data into training, and twenty percent of the data into training. This was done for each different outlier handling data sets created. 
614.The Random Forest model was initialized through the following code (for each different outlier handling data sets created): 5.It was then fit through running (for each different outlier handling data sets created): 6.Then, the predictions were generated by running (for each different outlier handling data sets created): 7.Scatterplots of the observed against predicted values were generated, (for each different outlier handling data sets created), to show visualizations of how well the model is predicting the data. The more data that is situated around the line of best fit, the better the model is performing. 
62A copy of one of the generated graphs is shown below: 8.The next step is generating the performance metrics of the models. The mean squared error was found using: A lower score for this metric is ideal.The R-squared value was found using: A score closer to 1 or –1 is ideal for this metric.Cross validation was performed through: Values should mimic those initially computed to indicate replicability of the model.
639.All performance metrics are saved into a PDF file when the following code is run: 10.Interpretations should be completed based on the results found. 11.If desired, a diagram of the model’s structure can be visualized by running the following code: DNN:1.Downloading the required libraries is the same as shown in the EDA module (page 24).2.Uploading the data is also the same as shown in the EDA module (pages 24-25).3.Splitting data into training and testing groups is important for capturing the ability of the model to accurately generate predictions. The model was split into eighty percent of the data into training, and twenty percent of the data into training. This was done for each different outlier handling data sets created. 4.The DNN model was initialized and compiled through the following code (for each different outlier handling data sets created): Any appropriate modifications can be made to the added layers and optimizer.
645.It was then fit through running (for each different outlier handling data sets created): The number of epochs can be changed if desired.6.Then, the predictions were generated by running (for each different outlier handling data sets created): 7.Scatterplots of the observed against predicted values were generated, (for each different outlier handling data sets created), to show visualizations of how well the model is predicting the data. The more data that is situated around the line of best fit, the better the model is performing. A copy of one of the generated graphs is shown below: 
658.The next step is generating the performance metrics of the models. The mean squared error was found using: A lower score for this metric is ideal.9.The R-squared value was found using: A score closer to 1 or –1 is ideal for this metric.10.All performance metrics are saved into a PDF file when the following code is run: 11.Interpretations should be completed based on the results found.12.If desired, a diagram of the model’s structure can be visualized by running the following code: Feature Engineering:1.Downloading the required libraries is the same as shown in the EDA module (page 24).2.Uploading the data is also the same as shown in the EDA module (pages 24-25).3.It is necessary for the data to be appropriately prepared for seasonal analysis. While the cleaning and preprocessing are the same as the logarithmic transformed data in the EDA 
66module, (pages 23-27), the following addition was included: 4.The modules were adjusted to include this information:Poisson Regression: Random Forest: 
67DNN (this module uses the same training and testing split as the Random Forest model): 5.After these models are generated, the predictions, visualizations, and performance metrics are computed the same as the modules of the matching models. These cells should be run. The only exception is the Poisson Regression, as it utilized a different package to generate the model. Its performance metrics were found using the following:
686.Interpretations should be completed based on the results found.7.The saving of any generated reports follows the same structure as those of prior modules, with the exception of the Poisson Regression model containing the structure listed above.
69For any individual with poor vision, this document can be hit through the “ctrl” and “+” symbols held down simultaneously, until the document can be viewed more comfortably. Any individuals that are colorblind, a grayscale version of this document has been included in a separate file.
70TroubleshootingIf any of the modules appear to be taking too long to generate, check that the program is not waiting for you to upload URL data or hit escape. The text box for this is small and can easily be missed.If the module has an error where something is not found and new data was uploaded, it is likely that the data or column names were not accurately adjusted to those now present.If the module has an error where something is not found and new data was not uploaded, check to ensure that all cells above the one have run. A cell that hasn’t been run could contain necessary saved information for the cells to come.There are lines of code that specify the shape of the data originally used. If the model does not run, it could be that the shape of the data does not match what was specified in the model.It is important to use data sets that are large enough to represent the population, but not too diverse for the model to learn accurately from. A model that begins with poor data quality will have poor performance.Again, a limitation of this product is that the models all perform poorly. The worldwide data is too diverse to learn from. Do not make any decisions based on the models generated in this product. It is recommended to use more localized data to train and analyze.Any errors or issues not anticipated can be researched through online queries, or contacting the developer (page 43).
71FAQCan I take this product and use it to analyze my own data?Yes! This product is meant to be used as a resource for future health research projects.Can new data be added?Yes. Ensure that there is proper merging, (examples are included in the EDA and Feature Engineering modules), or replacement of the column names throughout the product.Is log transformation always the best outlier handling technique?No. These models performed best with logarithmic transformed data, likely due to the extent of outliers that were present in the data. In other instances, another technique may be more efficient for different data sets. This is why the other techniques were left in the product’s code.Will the model be updated with new data as it is gathered?At this time, there is no intention of updating the data as it is gathered. The models did not perform well with the current data. It is likely that more data could create more confusion in the model, instead of improving performance. This product had the intentions of being a resource for steps future research should take, and what models to begin with. At this time, it is recommended to not use big, worldwide data for pandemic related data. More localized data should be used, and it is not believed that more data will change this outcome.Why did the original models not perform well?Through the logarithmic transformation, the mean squared errors were lowered to appropriate values. However, the R-squared values, predicted against observed graphs, and cross validation results did not show promising performance. This is likely because there is differences in reporting around the world. Lower populated or economic areas likely have less resources, and do not have as frequent reporting as other locations. This is likely causing the vast differences seen in the data and making it difficult for modules to learn. Therefore, more localized studies will likely improve model performance, as it showed some potential with the logarithmic transformed data in the Random Forest model.What are other potential methods to generate better model performance? At this time, it is recommended to take smaller portions of the data based on their location to improve model performance. However, it is possible that other feature engineering techniques could be explored and show a change in the performance of the models. Additionally, other modeling techniques that were not included in this analysis could be more adept at learning the nuances of this particular type of data.
72
73Help and Contact DetailsAny additional details on the functions used in this system can be directly found in the environment using ‘help(function_name)’ in a new cell. Questions on this product can be sent to the developer:Katelyn M. CampbellKCampbell129@my.gcu.edu
74GlossaryBox Plot: A box plot is a visualization of the data, showcasing the median, interquartile range, overall range, and outliers present within the data.Correlation: Correlation is identifying the relationship between two variables.Cross Validation: Cross validation is a model evaluation technique that creates multiple subsets of the data and varying which are a part of the training set, and which are a part of the testing set. In doing this, printing individual metrics can show if the results are replicable, and printing average results can provide the overall test metrics.Cumulative: Cumulative is the process of adding the previous value(s) to the current value in a data set. This can be used to show how much a variable has changed over time.Deep Neural Network (DNN): A Deep Neural Network is a model that is composed of many layers, utilized to gain a deep understanding of the data. Its name is a hint at the similarities of its structure and the biological neural composition,Differencing: Differencing is when the difference between two successive data points is calculated. This is often used to make time series data more stationary.Epochs: An epoch is one completion pass of training data when fitting a neural network.Exploratory Data Analysis (EDA): Exploratory Data Analysis is the process of attempting to gain an early understanding of the data, such as showing the shape through visualizations and/or summary statistics of the data.Feature Engineering: Feature engineering is the process of specializing a model to the structure of the data. For example, data with many outliers may want to transform the data in some manner to improve its results.Histogram: A histogram is a visual representation of the data, where the number of occurrences of a value in the data set is expressed in continuous intervals. The structure of its distribution is often an indicator if certain modeling is appropriate for the data, or if transformations on the data are needed.Interquartile Range (IQR): The interquartile range is the range, or distance, of the data from the seventy-fifth percentile to the twenty-fifth percentile.Line Graph: A line graph is a visual representation of data containing a numerical dependent and independent variable. All data points are represented in a continuous line.Logarithmic Transformation: A logarithmic transformation is when data has replaced each variable’s value with its logarithmic equivalent.
75Mean Squared Error: The mean squared error is the average squared differences between the observed values and the predicted values.Observed vs. Predicted Graph: The observed vs. Predicted graph is a scatterplot of the originally seen dependent variables against those that were predicted by a model.Outlier: An outlier is a data point that is distinct from other data points. This can be identified through three standard deviations away from the mean, or one and a half interquartile ranges away from the median.Pipeline: A pipeline is a structure of the processes that the data flows through in a project or product.Poisson Regression: A Poisson Regression is a linear model that uses the Poisson distribution to analyze the probability of the response variable. It is used with count data, specifically, and expects that data to behave linearly.Predictions: Predictions are estimates at what the dependent variable may be, given the independent variable.Pseudo R-Squared: Pseudo R-squared is the generalization of the calculation to R-squared for non-linear models (see R-squared).P-Value: The p-value is the probability of obtaining the observed results, or extreme results, if the null hypothesis is true.Random Forest: Random Forest is a machine learning algorithm that uses decision trees to make predictions. It combines the information learned in multiple subsets of data in decision trees to make predictions from.Rolling Mean: The rolling mean takes recent, prior values and averages them into a new value.R-Squared: R-squared is the measure of variance in the dependent variable that is explained by the independent variables. This is used in linear models.Scatterplot: A scatterplot is a visual representation of data containing a numerical dependent and independent variable. All data points are expressed as a series of coordinates. Seasonality: Seasonality is when time data shows a repetitive pattern, either through the time of day, week, month, year, or other time period.Standard Deviation: The standard deviation is the amount of variation a variable has away from its mean.Train-Test Split: Train-Test split is the process of splitting the data into a training subset, to fit the model to, and a testing subset, to compare its predictive results against.Trend: A trend is when time data shows a steady increase or decrease in the data over time.
76T-Statistic: The T-Statistic is the difference between standard errors of the sample mean from the population mean.User Interface: The user interface is the interactive points that exist for users in a data product.This glossary’s definitions were inspired from the text:Karpatne, A., Kumar, V., Steinbach, M. & Tan, P. (2018). Introduction to data mining (2nd ed.). Pearson. 
77ReferencesAlroy-Preis, S., Angulo, F. Anis, E., Brooks, N., Haas, E. J., Jodar, :., Khan, F., Levy, Y., McLaughlin, J. M., Mircus, G., Pan, K., Singer, S. R., Smaja, M., Southern, J., & Swerdlow, D. L. (2021). Impact and effectiveness of mRNA BNT162b2 vaccine against SARS-CoV-2 infections and COVID-19 cases, hospitalisations, and deaths following a nationwide vaccination campaign in Israel: an observational study using national surveillance data. Lancet, 397(10287), 1819-1829. doi: 10.1016/S0140-6736(21)00947-8Appel, C., Beltekian, D., Dattani, S., Gavrilov, D., Giattino, C., Hasell, J., Macdonald, B., Mathieu, E., Ortiz-Ospina, E., Ritchie, H., Rodes-Guirao, L., & Roser, M. (2025). COVID-19 pandemic [Data set]. Our World in Data. https://ourworldindata.org/coronavirusBarbeira, P. B., Bartolomeu, M. L., Castelli, J. M., Del Valle Juarez, M., Esperatti, M., Fuentes, N., Galligani, G., Giovacchini, C. M., Iummato, L. E., Laurora, M., Pennini, V., Pesce, M., Rearte, A. Rearte, R., Santoro, A., Tarragona, S., & Vizzotti, C. (2022). Effectiveness of rAd26-rAd5, ChAdOx1 nCoV-19, and BBIBP-CorV vaccines for risk of infection with SARS-CoV-2 and death due to COVID-19 in people older than 60 years in Argentina: a test-negative, case-control, and retrospective longitudinal study. Lancet, 399(10331), 1254-1264. doi: 10.1016/S0140 6736(22)00011-3 Barron, J. A., Buenrostro-Mariscal, R., Crossa, J., Montesinos-Lopez, A. Montesinos-Lopez, J. C., Montesinos-Lopez, O. A., & Salazar, E. (2021). Application of a Poisson deep neural network model for the prediction of count data in genome-based prediction. The Plant Genome, 14(3). https://doi.org/10.1002/tpg2.20118
78Brownlee, J. (2022). Your first deep learning project in Python with Keras step-by-step. Machine Learning Mastery. https://machinelearningmastery.com/tutorial-first-neural-network-python keras/Elliott, L., Loomis, D., & Richardson, D. B. (2005). Poisson regression analysis of ungrouped data. Occupational and Environmental Medicine, 62, 325-329. DOI: 10.1136/oem.2004.017459 Fandohan, A. B., Kakaï, R. G., & Mushaglusa, C. Z. (2022). Random forest in count data modelling: An analysis of the influence of data features and overdispersion on regression performance. Journal of Probability and Statistics, 1. https://doi.org/10.1155/2022/2833537 GeeksforGeeks. (2025). Ranom forest regression in Python. https://www.geeksforgeeks.org/random-forest-regression-in-python/Gîrjău, M., Horton, N. J., & Prium, R. (2023). Fostering better coding practices for data scientists. HDSR. https://hdsr.mitpress.mit.edu/pub/8wsiqh1c/release/4Katla, N. (2020). Poisson regression implementation- Python. Medium. https://medium.com/@kn12/poisson-regression-implementation-python-28d15e95dc15Karpatne, A., Kumar, V., Steinbach, M. & Tan, P. (2018). Introduction to data mining (2nd ed.). Pearson. Liu, J. (2024). Navigating the financial landscape: The power and limitations of the ARIMA model. Highlights in Science, Engineering and Technology, 88, 747-752. https://drpress.org/ojs/index.php/HSET/article/view/19082/18645
79National Cancer Institute. (2023). Cleaning data: The basics. Center for Biomedical Informatics and Information Technology. https://datascience.cancer.gov/training/learn-data-science/clean data-basicsThe Pennsylvania State University. (n.d.). 9: Poisson Regression. https://online.stat.psu.edu/stat504/book/export/html/782#:~:text=Interpretations,tabletop %20of%20a%20certain%20area Plotly. (n.d.). Creating and updating figures in Python. https://plotly.com/python/creating-and updating-figures/#updating-figuresSarahjane3102. (2022). How to split the dataset With scikit-learn’s train_test_split() function GeeksforGeeks. https://www.geeksforgeeks.org/how-to-split-the-dataset-with-scikit-learns train_test_split-function
80Big Data Analysis of COVID-19 Vaccinations and COVID-19 Related Deaths: A System Administration User GuideBy Katelyn M. Campbell
81System Administration User Guide:Big Data Analysis of COVID-19 Vaccinations and COVID-19 Related DeathsKatelyn M. CampbellCollege of Engineering and TechnologyDSC-590-O500 Data Science Capstone ProjectProfessor Kevin AbreuJune 25, 2025
82Copyright © 2025 by Katelyn M. Campbell All rights reserved.No portion of this book may be reproduced in any form without written permission from the publisher or author, except as permitted by U.S. copyright law.
83
84Table of Contents•System Overview83•System Configuration93•System Maintenance95•Security Related Processes104•Appendices105•Table of Figures106Please use Ctrl + F to search this document.
85System OverviewIntroductionThe software accompanying the project, Modeling of COVID-19 Vaccination and Mortality Big Data, is a system designed to take data on COVID-19 vaccination counts, COVID-19 related mortality counts, dates, and countries from Our World in Data to generate predictive models. There is the possibility of adding to or changing the data source, however, appropriate changes will need to be made for the data columns. Modeling types currently available are Poisson Regression, Random Forest, Deep Neural Network, feature engineering to include date information with the above models, and specification on utilizing data from the United States and Canada for the above listed models. The purpose of this is to identify the best possible model for any given big data set. This is a cloud based software, using GitHub’s Codespaces. Therefore, a web browser, such as Google Chrome, internet availability, a GitHub account, Python 3.12, Microsoft VS Code, and a compatible Operating System, such as Windows 10, are required for its use.AudienceCurrently, the GitHub repository is set as public, with no outside permissions given to write. It has only been directly shared amongst professors at Grand Canyon University. In the future, this guide could serve as a source for system administrators in software management and related processes.Overview of System ArchitectureIn the system, the following folders are can be found: __pycache__, .devcontainer, Clean_Folder, Data, DNN_Folder, EDA_Folder, Feature_Engineering_Folder, Poisson_Folder, Random_Forest_Folder, Regional_Folder, and templates, as can be seen in the following image.Figure 1
86__pycache____pycache__ folders exist due to Python running a .py file. When ran, the code is compiled into a bytecode, allowing faster execution the next time the code is run..devcontainer.devcontainer allows for the product to be reproducible. While it allows for others to copy the codes for their own projects, it also provides a way for Codespace to easily be refreshed, as will be discussed further in System Maintenance.Clean_FolderThe Clean_Folder contains a __pycache__ file, the .py file Capstone_Milestone_3_Clean.py, and the csv files data_clean.csv, data_log.csv, data_nomean_out.csv, and data_nomedian_out.csv. Capstone_Milestone_3_Clean.py contains a help guide for users, as well as underlying code to run the app_clean.py file. Its purpose is to aid in properly cleaning the data for use in future .py files. All of the csv files are within this folder due to a save function in app_clean.py. Data_clean.csv holds a csv file where the data has been cleaned, with the exception of outlier handling. Data_log.csv holds the clean data where outliers have been taken care of through logarithmic transformation. Data_nomean_out.csv also holds the clean data, however, outliers over three standard deviaitons have been removed. Data_nomedian_out.csv is 
87similar to data_nomean_out.csv, but any outliers over one and a half interquartile ranges away from the median have been removed. The structure of the folder can be seen below.Figure 2DataThe Data folder is a location where the data csv files have been manually saved. This contains the original data from Our World in Data, daily-covid-19-vaccine-doses-administered.csv and daily-new-confirmed-covid-19-deaths-per-million-people.csv. Additionally, the csv files data_clean.csv, data_log.csv, data_nomean_out.csv, and data_nomedian_out.csv were manually saved here, as a backup in case the save function in app_clean.py fails at any point. The structure of the folder can be seen in the image below.Figure 3
88DNN_FolderThe DNN_Folder contains the .py file Capstone_Milestone_3_DNN.py. This file accompanies app_dnn.py, as it has a help section and underlying code. Its purpose is to help produce the Deep Neural Network model. The structure of the folder can be seen in the following image. Figure 4EDA_FolderThe EDA_Folder contains the .py file Capstone_Milestone_3_EDA.py and a __pycache__ file. This file accompanies app_eda.py, as it has a help section and underlying code. Its purpose is to help perform Exploratory Data Analysis through data summaries and creation of a multitude of graphs. The structure of the folder can be seen in the following image.Figure 5
89Feature_Engineering_Folder StructureThe Feature_Engineering_Folder contains the .py file Capstone_Milestone_3_Feature_Engineering.py and a __pycache__ file. This .py file can be used to run a Poisson Regression, Random Forest, and DNN model, while including the date of the data in order to identify if seasonality components improve the performance of the models.Figure 6Poisson_Folder StructureThe Poisson_Folder contains the .py file Capstone_Milestone_3_Poisson.py and a __pycache__ file. This file accompanies app_poisson.py, as it has a help section and underlying code. Its purpose is to help produce the Poisson Regression model. The structure of the folder can be seen in the following image.Figure 7
90Random_Forest_Folder StructureThe Random_Forest_Folder contains the .py file Capstone_Milestone_3_Random_Forest.py and a __pycache__ file. This file accompanies app_rf.py, as it has a help section and underlying code. Its purpose is to help produce the Random Forest model. The structure of the folder can be seen in the following image.Figure 8Regional_Folder StructureThe Regional_Folder contains three .py files, app_regional_dnn.py, app_regional_poisson.py, and app_regional_rf.py. These files perform the same models, however, they run only data on the United States and Canada. The structure of the folder can be seen in the following image.Figure 9TemplatesThe templates folder contains the html file analysis_result.html, which outlines the structure of how each .html file generated in the project will be organized. Its focus is on how the performance results are shown in the web browser. An image below shows the folder structure.
91Figure 10.py FilesThere are eight .py files: addpy_clean_pdf.py, app_clean.py, app_dnn.py, app_eda_pdf.py, app_eda.py, app_featureeng.py, app_poisson.py, and app_rf.py. Addpy_clean_pdf.py creates a pdf file of all the information that can be seen in the browser of app_clean.py. App_clean.py, in conjunction with Capstone_Milestone_3_Clean.py in the Clean_Folder, produces the web browser of all of the information on the data cleaning. App_dnn.py, in conjunction with Capstone_Milestone_3_DNN.py in the DNN_Folder, produces the web browser of all of the information on the Deep Neural Network model. App_eda_pdf.py, is similar to addpy_clean_pdf.py, in that it produces a pdf file of all the information contained in the browser produced from app_eda.py. App_eda.py, in conjunction with Capstone_Milestone_3_EDA.py in the EDA_Folder, produces the web browser of all of the information and graphs produced for exploratory data analysis. App_feateng.py, in conjunction with Capstone_Milestone_3_Feature_Engineering.py in the Feature_Engineering_Folder, produces the web browser of all of the information and 
92performance metrics of the feature engineered models. App_poisson.py, in conjunction with Capstone_Milestone_3_Poisson.py in the Poisson_Folder, produces the web browser of all of the information and performance metrics of the feature engineered models. Finally, app_rf.py, in conjunction with Capstone_Milestone_3_Random_forest.py in the Random_Forest_Folder, produces the web browser of all of the information and performance metrics of the feature engineered models. The .py files can be seen in the image below.Figure 11MarkdownThe Markdown contains all of the general information on the models, graphical user interface elements, system security, system revisions, and references used when creating the project. An image below shows the structure of the markdown.Figure 12
93Requirements.txtThe requirements.txt includes some of the necessary libraries for running the Python code. More detailed explanations can be found within the .py files contained in the folders. An image below shows the structure of the requirements.Figure 13
94
95System ConfigurationSoftwareThe required software for this product is:•Python 3.12•Libraries:οDash♣.dependenciesοFlaskοgraphvizοIoοMarkupsafeοMathοMatplotlib♣.image♣.pyplotοNumpyοOsοPandasοPlotly♣.express♣.graph_objs♣.subplotsοScipy♣.statsοSeabornοSklearn♣.ensemble♣.linear-model♣.metrics♣.model_selection♣.preprocessingοStatisticsοStatsmodels♣.apiοSys οTensorflow♣.keras.layers
96♣.keras.models♣.keras.optimizersοTimeοUrllib♣.request•Microsoft Visual Studio Code•Jupyter Notebook•Windows 11HardwareThe minimal recommended hardware, as it was used in product development, is:•CPU- Intel(R) Core (TM) i7-8550U•RAM- 16 GB•Hard drive- Hard disk drive 2 TB•Motherboard- ASUS Q525 Model•OS- Windows 11NetworkThe required network involves a stable internet connection and access to the GitHub repository.User AccessViewing access is currently set to public, and permission for writing will need to be requested from the product creator, Katelyn M. Campbell. A GitHub account is required to work on the project in GitHub Codespaces.
97System MaintenanceTo ensure system functionality, the following maintenance plan should be completed.Daily tasks:•Check for any communication from users regarding the system. This may include troubleshooting needs, or recommended improvements to the system.Weekly tasks:•Updating Python packages.οThis can be done by applying the following in the terminal:♣pip list –outdated•This will list all outdated packages.Figure 14•The output should appear like this:Figure 15
98♣pip install --upgrade <package_name>•Any listed packages should be written in place of the < >Figure 16•The output should appear as:Figure 17
99•Cleaning out __pycache__ files.οClearing the cache will improve system performance, and they will be regenerated at each run iteration of the program.οTo perform this, right click on the __pycache__ file, and hit permanently delete.Figure 18•Updating data.
100οChecking on if any new updates have been added to the Our World in Data site could impact model performance. Therefore, it is important to check if new data should be added.♣Follow the link in the citation below.♣Find “Download this dataset”Figure 19♣Select the data sets “Cases and Deaths” and “Vaccinations”Figure 20
101♣Right click on the Data folder and select “Upload”Figure 21
102♣Select the files from the Downloads folder of the computer. The original file names were “daily-covid-19-vaccine-doses-administered.csv" and “daily-new-confirmed-covid-19-deaths-per-million-people.csv."•If the names are the same, choose to overwrite the previous data. If not, delete the old data files and rename the new to the prior data names. This will allow for there to be no need for revisions when calling to the data in the code.οSource: Appel, C., Beltekian, D., Dattani, S., Gavrilov, D., Giattino, C., Hasell, J., Macdonald, B., Mathieu, E., Ortiz-Ospina, E., Ritchie, H., Rodes-Guirao, L., & Roser, M. (2024). COVID-19 pandemic [Data set]. Our World in Data. https://ourworldindata.org/coronavirusMonthly tasks:• Checking model performance.οEnsuring that the current recommendations given the data are still applicable, it is important to rerun the program and evaluate the performance of the models.οTo perform this, select one of the app_<model_name>.py files and hit the run icon.Figure 22οA pop-up should appear in the bottom right corner of the screen. Select “Open in Browser”Figure 23
103οAfter allowing the model to run, a graph should be generated, along with performance metrics. Compare this to the text found after the message “(EXAMPLE- WILL CHANGE DEPENDENT ON ITERATION).” If any significant findings are found, the content and user guide must be updated to reflect this. This should be performed for all models. An example output is below.Figure 24•Refreshing GitHub Codespace.οIn order to ensure that the latest versions are being utilized, it is important to refresh the development environment on Codespace.
104οTo perform this, hit the “F1” and a text box should open.οType in “Rebuild Container” and select “Codespaces: Rebuild Container.”♣This will reset the workspace, which should clear out the cache and update the environment.Figure 25After changes:•Model performance should be checked after each change. Any notable performance metrics differencing should be updated in the comments and user guides, as this may influence the recommendations on which model is the most efficient.•Mirror cloning should be performed to ensure that the code is backed up, in case of accidental deletion. This can be done through git clone –mirror. There will be a local backup of the repository available.οTo do this, go to the bash terminal and type “git clone --mirror https://github.com/kmmckenz/my-data-product-poisson.git” and hit “Enter”Figure 26
105οThe output should appear like this:Figure 27 
106Security Related ProcessesAccess and AuthenticationThe GitHub repository is set to public, so anyone has access to view the code. There is no one currently added as a collaborator to write or make changes to the code. Only the owner, Katelyn M. Campbell, is capable of directly adding people to have any writing access. Limited access will be given to future collaborators. Roles will be restricted to only mandatory needs of that user, preventing any unauthorized contributions.GitHub username and password system will be authentication to verify user identity. There is no identifiable information in the data, so the only security issue is ensuring the integrity and validity of the code.BackupMirror cloning, as discussed in the system maintenance, will be utilized as the backup for the GitHub repository. The entirety of the repository will be copied, ensuring that any accidental deletion or difficulties accessing the repository are mitigated.Networking and ConnectivityTo maintain security, it is important to regularly check that the computer being used to access the repository and the web browser itself are up to date with the latest security. This will prevent any vulnerabilities being accessed on the user's end. Additionally, GitHub has its own underlying network security to protect the repository.CablingAs GitHub Codespaces is a virtual environment, there are no security concerns involving cabling. Best practices in protecting passwords and using a secure computer and browser are the main methods of protecting the repository.Critical ServicesCritical services include the CSV files, Python scripts, and the Flask/Dash web server. The web server requires proper execution of the scripts, and the scripts require access to the data stored. Regular maintenance, as outlined in System Maintenance, will ensure proper functioning, implement updates, and identify any errors to address, ensuring the product is working as anticipated.
107Appendices__pycache__ This is a directory that Python uses to store compiled bytecode, which allows the system to execute more quickly. Deletion of this is not damaging to the system. It will regenerate the next iteration of code.Codespaces This is a cloud-based environment available on GitHub. It allows users to directly code into the browser.Flask/Dash This is a Python library that provides the ability to build an interactive web browser.Mirror cloning This is a method to perform a complete backup on all aspects of the repository.Public/Private repositories A public repository is one where anyone has access to view it, whereas a private repository only allows users given explicit access.Rebuild container This is a way to refresh the Codespace environment, making it up to date.Any details on the models themselves and their applications can be found in the User Guide. 
108Table of FiguresFigure NumberFigure TitlePage Number1Overview of System Architecture 82-832Clean_Folder843Data Folder844DNN_Folder855EDA_Folder856Feature_Engineering_Folder85-867Poisson_Folder868Random_Forest_Folder869Regional_Folder8710Templates87-8811.py Files8912Markdown89-9013Reguirements.txt90-9114Finding Outdated Packages (Input)9415Finding Outdated Packages (Output)94-9516Updating Outdated Packages (Input)9517Updating Outdated Packages (Output)95-9618Cleaning Out __pycache__ Files9619Updating Data9720Selecting Data Files97-9821Uploading Data9822Running Model9923Opening Browser99-10024Model Performance100-10125Rebuild Container10126Mirror Cloning (Input)102-10327Mirror Cloning (Output)103
109Test PlanModeling of COVID-19 Vaccination and Mortality Big DataAuthor: Katelyn M. CampbellDate: 6/11/2025The Modeling of COVID-19 Vaccination and Mortality Big Data is a project exploring what available techniques for handling pandemic related big data are most effective at modeling. This test plan will ensure the functionality of stepwise handling and modeling of data, as well as exploring the performance metrics of the models.1.Analyze the Producta.This product is designed for researchers trying to identify a starting model for big data that is similar in nature to the pandemic.b.It is intended to be used for identifying the best predictive model for the given data set, along with showcasing the observed against predicted values, performance metrics, and cross validating results.c.Users will use the given data or then upload their own. A cleaning and exploratory data analysis should be ran next. There are then three predictive models for the big data: Poisson Regression, Random Forest, and DNN. If these models do not produce the best results, there is a section for running the models while considering seasonality. If these still are not successful, all three models have a section to run the data based on regions, specifically the United States and Canada.d.The project is available to run on GitHub’s Codespace, using Python as the coding language. Other involved technologies include CPU- Intel(R) Core (TM) i7-8550U, RAM- 16 GB, Hard drive- Hard disk drive 2 TB, Motherboard- ASUS Q525 Model, OS- Windows 11. The original concept for the project was designed using the following: Program- Microsoft Visual Studio Code and Software- Juypter Notebook.2.Design the Test Strategya.The scope of the testing for the project is to ensure data cleaning occurs, data exploration techniques are available, and all models can produce graphs and performance metrics.b.The data cleaning should prepare the data and save data sets for the modeling. Exploratory data analysis should provide information on the data that could be used to identify what models may or may not be appropriate for the data. All models need to generate graphs and performance metrics for the user to analyze. Additionally, data should be available to flow throughout the project.
110c.Risks include data set not being appropriate for the modeling, no model showing ideal performance metrics, and misinterpretation of results. If the data set is not appropriate for the modeling, then this will likely be easily identifiable in the performance metrics, if not earlier in the cleaning and exploratory data analysis. Random Forest and DNN models were chosen for their versatility, which should mitigate some of the risks. There is a chance that no model is appropriate for the data set. If the big data is too diverse, it could cause all models to perform poorly. The feature engineering portion and regional portion of the project were created to mitigate this risk, but is not a guarantee. Overall, all who use this project should analysis their individual results completely. No model was shown to have ideal performance in the current project, as even the best performance had a wide variety in the cross validation results. While utilizing a logarithmic transformation to handle outliers, looking at data regionally, and a Random Forest was shown to have the best results, it is still not in a state where decisions could be made from the model.d.Testing will occur by running all functions of the project on GitHub Codespace and notating each step by the creator over the next week.3.Define the Test Objectivea.The testing will involve data loading, data cleaning, data saving, logs of tasks, html and pdf availability, generation of graphs, modeling and performance metrics.b.For data loading, the goal is to ensure proper loading of csv file of data. If this does not occur, then an error message should be generated. There is an option to load data through an html file, but this is currently disabled due to it not being in use. The data cleaning should remove outliers in a variety of ways, remove missing values, remove duplicated observations, and show data types to ensure they are appropriate for the data. If this does not occur, an error message should generate. For data saving, after the data sets are cleaned, they should save to four different data sets: cleaned data (no outlier handling), data with outliers removed over 3 standard deviations away, data with outliers removed over 1.5 IQR’s away, and data logarithmically transformed. All cleaned data should be saved under the Clean_Folder and an error message will generate if this does not occur. All tasks to be completed will have a log of when the task was initialized and when it was completed, to show the processing and the amount of time it took. If there is an error, then the log will not show in the html or PDF. All related graphs should generate in the html and PDF, with availability to save in the html. If this does not occur, the graphs will not show and an error message should populate.All models should run through the data sets after selection from the dropdown menu. If there are any errors, an error should show, and the graphs and performance metrics will not appear in the html. Performance metrics of R-Squared, MSE, and cross 
111validation of these should run. If these do not, then there is likely an error within the model. Some models will show under performance, and any inferences made from that model should be taken with caution, or the model itself should be disregarded as a viable predictive model.4.Define Test Criteriaa.Each task should show a logged step, no errors, all graphs should generate and be operational, and all comments and performance metrics should be printed. As for the models, to be trustworthy, the model should show ideal performance metrics.b.A complete pass would be logged steps are shown in the html and PDF’s generated, no error messages are reported in the terminal or the html and PDF’s, graphs should have selection of what data set to use (if appropriate) and should produce results, including the performance metrics, after the data set is chosen, comments should print out with results from the most recent use of the project creator, and performance metrics should be printed in the html and PDF’s. For a model to be ideal, the R-squared value should be high, between 0.8 and 1, the MSE should be low in context of the data set used, and cross validation should show replicable results. 5.Resource Planninga.The creator, Katelyn M. Campbell, will be running all testing. Input from Professor Kevin Abreu and fellow classmates will be implemented to guide the process.b.GitHub Repositories and Codespace are necessary requirements for the testing, as well as the necessary Python libraries.6.Plan Test Environmenta.Hardware and software required to test the project include: CPU- Intel(R) Core (TM) i7-8550U, RAM- 16 GB, Hard drive- Hard disk drive 2 TB, Motherboard- ASUS Q525 Model, OS- Windows 11,Language- Python, GitHub Repository and GitHub Codespace.7.Determine Test Deliverables will include:a.Test plan documentb.Test casesc.Test scriptsd.Error logs
112Performance AnalysisModeling of COVID-19 Vaccination and Mortality Big DataAuthor: Katelyn M. CampbellDate: 6/11/2025Module Test CasesTest Case Name: app_clean.pyPriority: HighModule: Data CleaningTest Objective: To clean data from outliers, repeated observations, missing observations, and incorrect data types.StepTest DetailExpected ResultsProblem/Issue1Load dataData is loaded from a csv fileNone identified2Data scrubbingData has the confirmed deaths converted to individual counts, (not per million people), the day in date time format, null values removed, and duplicated values removed. This is now saved as data_clean.None identified3Outlier processingThree new data sets are generated: data_nomean_out, (outliers over 3 standard deviations away are removed), data_nomedian_out, (outliers over 1.5 IQRs away are removed), and data_log, (outliers are logarithmically transformed out of the data.None identified4Data scrubbing (part 2)The data scrubbing process is repeated on the data with the outliers processed.None identified5About cleaningContent describing the cleaning process is printed.None identified6Data savedAll data sets are saved to be available for use in later modules.None identifiedTest Case Name: addpy_clean_pdf.pyPriority: LowModule: Data Cleaning
113Test Objective: To print out a pdf file of findings from data cleaning.StepTest DetailExpected ResultsProblem/Issue1Load data logLog of when the data was loaded and if there are any errors is producedNone identified2 Load content logLog of when the content was loaded and if there are any errors is producedNone identified3Load scrubbed data logLog of when the data was scrubbed and if there are any errors is producedNone identified4Load outlier processing logLog of when the data had its outliers processed and if there are any errors is producedNone identified5Print details in htmlAll of the above details are printed in an html fileNone identified6Make details available in a PDFAll of the above details are printed in a PDF fileNone identifiedTest Case Name: app_eda.pyPriority: LowModule: Exploratory Data AnalysisTest Objective: To explore the shape and structure of the data.StepTest DetailExpected ResultsProblem/Issue1Data loadedData is loaded from the saved filesNone identified2Descriptive statisticsDescriptive statistics are found on all saved data filesNone identified3Unique countriesUnique countries are identified to aid in the creation of interactive graphs.None identified4Graphs are generatedBox plot of vaccination data, box plot of death data, histogram of vaccination data, histogram of death data, line graph of vaccination data, and line graph of death data are all generated with the ability to filter between countries. Scatter plot of vaccination against deaths, rolling means (weekly, monthly, None identified
114and at 180 days), and differencing graphs are also generated.5Content is loadedContent describing the EDA findings is loaded and printed.None identified6All graphs and content in htmlAll of the above is made available in an html.None identifiedTest Case Name: app_eda_pdf.pyPriority: LowModule: Exploratory Data AnalysisTest Objective: To print out a pdf of the results from exploring the data.StepTest DetailExpected ResultsProblem/Issue1Log of loaded dataLog of when the data was loaded is printedNone identified2Log/content of descriptive statisticsLog of when the descriptive statistics were performed and their findings are printedNone identified3Unique countriesThe countries unique in the data are foundNone identified4Graphs are generatedAll graphs listed above are printedNone identified5Content is loadedThe content describing the EDA is loaded and printedNone identified6PDF is generatedA PDF of all the above details is generatedNone identifiedTest Case Name: app_poisson.pyPriority: HighModule: Poisson Regression Model (Big Data)Test Objective: To generate a Poisson model on big data and identify if it produces performance metrics that are satisfactory.StepTest DetailExpected ResultsProblem/Issue1Data loadedData sets created from above steps are loadedNone identified2Description of past analysis printedComment that explains the most recent findings and analysis are printedNone identified3Screen layout The layout of the screen with the graphs and text is setNone identified
1154Graph data set selectionSelecting if data_clean, data_nomean_out, data_nomedian_out, and data_log is chosen for the graph and metricsNone identified5X reshapedX is reshaped to be able to use with sklearnNone identified6ModelingThe model is fit and performance metrics are foundModel fit is poor- clean data: R-squared 0.0005 and MSE 40808354590434.68875, no mean: R-squared is 0.0012 and MSE is 10736283315473.1211, no median: R-squared 0.0121 and MSE 1298074915309.7244, and log data R-squared 0.1440 and MSE 37.1173. Despite this, model is generating results.7Performance textThe text of how the model is performing is printed on the graph.None identified8Observed against predicted values graphThe scatter plot of the observed against predicted values is generated and shown in the html.Poor performance, but graphs are generated.Test Case Name: app_rf.pyPriority: HighModule: Random Forest Model (Big Data)
116Test Objective: To generate a Random Forest model on big data and identify if it produces performance metrics that are satisfactory.StepTest DetailExpected ResultsProblem/Issue1Data loadedData sets created from above steps are loadedNone identified2Description of past analysis printedComment that explains the most recent findings and analysis are printedNone identified3Screen layout The layout of the screen with the graphs and text is setNone identified4Graph data set selectionSelecting if data_clean, data_nomean_out, data_nomedian_out, and data_log is chosen for the graph and metricsNone identified5X reshapedX is reshaped to be able to use with sklearnNone identified6ModelingThe model is fit and performance metrics are foundModel fit is poor- clean data: R-squared 0.4349 and MSE 23072378498076.3320, no mean: R-squared is 0.4856 and MSE is 
1175528782496558.7041, no median: R-squared 0.4542 and MSE 717160401233.7115, and log data R-squared 18.8799 and MSE 0.5646. Despite this, model is generating results.7Performance textThe text of how the model is performing is printed on the graph.None identified8Observed against predicted values graphThe scatter plot of the observed against predicted values is generated and shown in the html.Poor performance, but graphs are generated.Test Case Name: app_dnn.pyPriority: HighModule: Deep Neural Network Model (Big Data)Test Objective: To generate a DNN model on big data and identify if it produces performance metrics that are satisfactory.StepTest DetailExpected ResultsProblem/Issue1Data loadedData sets created from above steps are loadedNone identified
1182Description of past analysis printedComment that explains the most recent findings and analysis are printedNone identified3Screen layout The layout of the screen with the graphs and text is setNone identified4Graph data set selectionSelecting if data_clean, data_nomean_out, data_nomedian_out, and data_log is chosen for the graph and metricsNone identified5X reshapedX is reshaped to be able to use with sklearnNone identified6ModelingThe model is layers are added, the data is fit, and performance metrics are foundModel fit is poor- clean data: R-squared –0.595 and MSE 43293366365372.5703, no mean: R-squared is –0.1771 and MSE is 12524823465418.0684, no median: R-squared –0.2408 and MSE 1624004621713.4929, and log data R-squared 
1190.1494 and MSE 36.7312. Despite this, model is generating results.7Performance textThe text of how the model is performing is printed on the graph.None identified8Observed against predicted values graphThe scatter plot of the observed against predicted values is generated and shown in the html.Poor performance, but graphs are generated.Test Case Name: app_feateng.pyPriority: MediumModule: Feature Engineering Models (Big Data)Test Objective: To generate a Poisson, Random Forest, and DNN model on big data while considering potential seasonality trends and identify if they produce performance metrics that are satisfactory.StepTest DetailExpected ResultsProblem/Issue1Data loadData saved from previous modules is loadedNone identified2Data splitData is split into 80% training and 20% testing.None identified3Predictions graphThe predictions graph is laid out, including selecting what model types to run.None identified4Screen layoutThe screen layout of the graphs and performance metrics is specified.None identified5ModelPoisson, Random Forest, and DNN are ran while considering the dates of the data, and performance metrics are generated.Models are running, but poorly. Poisson Regression (clean data): R-squared –0.0 and MSE 
12016469083628447.56, (no mean data): R-squared –0.01 and MSE 6128309046166.24, (no median data): R-squared 0.08 and MSE 372385075078.10, and (log): R-squared 0.11 and MSE 53.37. Random Forest (clean): R-squared –1.64 and MSE 18314034231614.80, (no mean): R-squared -0.47 and MSE 8183485242633.13, (no median): R-squared –0.05 and MSE 468202277437.36, and (log): R-squared 0.14 and MSE 52.36. DNN (clean): R-squared -0.22 and MSE 8979934670731.10, (no mean): R-squared –0.14 and MSE 8043500095703.07, (no median): R-squared –0.07 and MSE 
121336632458908.09, and (log): R-squared 0.10 and MSE 47.65.Test Case Name: app_regional_poisson.pyPriority: HighModule: Poisson Regression Model (Regional Data)Test Objective: To generate a Poisson model on regional data and identify if it produces performance metrics that are satisfactory.StepTest DetailExpected ResultsProblem/Issue1Data loadedData sets created from above steps are loadedNone identified2Comment printedComment that explains the most recent findings and analysis are printedNone identified3Screen layoutThe layout of the screen with the graphs and text is setNone identified4ModelModel is generated, performance metrics are found, and graph is created.All aspects are functional, but models are performing poorly: US MSE: 1.0748US R²: 0.0101US CV R²: -0.7260 ± 0.5876US CV MSE: 1.2258 ± 0.3212Canada MSE: 1.0347Canada R²: 0.0785Canada CV R²: -0.6371 ± 0.2532Canada CV MSE: 1.2662 ± 0.4745
122Test Case Name: app_regional_rf.pyPriority: HighModule: Random Forest Model (Regional)Test Objective: To generate a Random Forest model on regional data and identify if it produces performance metrics that are satisfactory.StepTest DetailExpected ResultsProblem/Issue1Data loadedData sets created from above steps are loadedNone identified2Comment printedComment that explains the most recent findings and analysis are printedNone identified3Screen layoutThe layout of the screen with the graphs and text is setNone identified4ModelModel is generated, performance metrics are found, and graph is created.All aspects are functional, but models are performing significantly better, but cross validation is poor for R-squared: US MSE: 0.1980US R²: 0.8176US CV R²: -1.4249 ± 0.6438US CV MSE: 1.6988 ± 0.2780Canada MSE: 0.1828
123Canada R²: 0.8372Canada CV R²: -1.2408 ± 0.8239Canada CV MSE: 1.6008 ± 0.4555Test Case Name: app_regional_dnn.pyPriority: HighModule: Deep Neural Network Model (Regional)Test Objective: To generate a DNN model on regional data and identify if it produces performance metrics that are satisfactory.StepTest DetailExpected ResultsProblem/Issue1Data loadedData sets created from above steps are loadedNone identified2Comment printedComment that explains the most recent findings and analysis are printedNone identified3Screen layoutThe layout of the screen with the graphs and text is setNone identified4ModelModel is generated, performance metrics are found, and graph is created.All aspects are functional, but models are performing poorly: US MSE: 1.1003US R²: -0.0135Canada MSE: 1.1106Canada R²: 0.0110
124Requirements TestingComponent: Data CleaningName of Developer: Katelyn M. CampbellName of Reviewer: Katelyn M. CampbellChecklistTypePassCommentsFunctionalityPassedData was successfully cleaned, producing details on the execution of the cleaning process.PerformancePassedOutputs did not have any missed commands and were computed in a timely manner.Component: Exploratory Data AnalysisName of Developer: Katelyn M. CampbellName of Reviewer: Katelyn M. CampbellChecklistTypePassCommentsFunctionalityPassedData was successfully explored, producing statistical findings and graphical representations.PerformancePassedOutputs generated without error and were computed in a timely manner.Component: Poisson Regression Model (Big Data)Name of Developer: Katelyn M. CampbellName of Reviewer: Katelyn M. CampbellChecklistTypePassCommentsFunctionalityPassedModels were successfully generated, and graphical and 
125performance metrics were output.PerformanceFailedR-squared values were too low for a trustworthy model.Component: Random Forest Model (Big Data)Name of Developer: Katelyn M. CampbellName of Reviewer: Katelyn M. CampbellChecklistTypePassCommentsFunctionalityPassedModels were successfully generated, and graphical and performance metrics were output.PerformanceFailedR-squared values were too low for a trustworthy model.Component: Deep Neural Network (Big Data)Name of Developer: Katelyn M. CampbellName of Reviewer: Katelyn M. CampbellChecklistTypePassCommentsFunctionalityPassedModels were successfully generated, and graphical and performance metrics were output.PerformanceFailedR-squared values were too low for a trustworthy model.Component: Feature Engineered ModelsName of Developer: Katelyn M. CampbellName of Reviewer: Katelyn M. CampbellChecklistTypePassCommentsFunctionalityPassedModels were successfully generated, and graphical and 
126performance metrics were output.PerformanceFailedR-squared values were too low for a trustworthy model.Component: Poisson Regression Model (Regional)Name of Developer: Katelyn M. CampbellName of Reviewer: Katelyn M. CampbellChecklistTypePassCommentsFunctionalityPassedModel was successfully generated, and graphical and performance metrics were output.PerformanceFailedR-squared values were too low for a trustworthy model, and cross validation did not show consistency.Component: Random Forest Model (Regional)Name of Developer: Katelyn M. CampbellName of Reviewer: Katelyn M. CampbellChecklistTypePassCommentsFunctionalityPassedModel was successfully generated, and graphical and performance metrics were output.PerformancePartialR-squared and MSE scores indicated good performance, but cross validation showed the model is still not producing reliable results consistently.Component: Deep Neural Network Model (Regional)Name of Developer: Katelyn M. CampbellName of Reviewer: Katelyn M. Campbell
127ChecklistTypePassCommentsFunctionalityPassedModel was successfully generated, and graphical and performance metrics were output.PerformanceFailedR-squared values were too low for a trustworthy model.Test ScriptsTest scripts can be found at: https://github.com/codespaces/literate-memory-wrxqrv7wgqppcvv95 Error LogsNo errors were found in the last final run of the project to notate.System TestingThe system was tested end-to-end, beginning with the cleaning of the original data set. Once this was performed, the Exploratory Data Analysis was completed. Three model approaches were then implemented- Poisson Regression, Random Forest, and Deep Neural Network. To get a more complete picture of model performance, feature engineered models and regional models were then run.All outputs, such as written content, statistical summaries, performance metrics, and graphs, were generated, and no errors were found during the system’s execution. While the flow of data between the different applications is up to the user, the User Guide clarifies that the above description is the proper process and usage.As the primary goal of the models is to contribute more knowledge to future researchers attempting to analyze big data, either of the COVID-19 pandemic or similar, the requirements of the system were met. Any users will be able to find performance metrics and graphs for each model, allowing them to develop their own conclusions on what modeling technique is the most appropriate.
128EvaluationRequirementOutcomeJustificationPerform an exploratory data analysis on COVID-19 vaccination data.MetEDA is conducted, complete with tables of summary statistics and visual aids.Conduct a Poisson regression, Random Forest, and DNN model to find patterns between vaccination dose status and mortality rate.MetAll models are functional.Predict mortality rates given vaccination status.MetAll models were able to make predictions.Analyze model performance through observed values against predicted values graphs, mean standard error, R-squared/Pseudo R-Squared, and cross validation.MetAll metrics and graphs were generated.If the model does not perform well, then look for other alternatives in models, such as feature engineering techniques or subsetting the data by region.MetSubsetting data by the regions the United States and Canada was completed, and models are functional.Compare models to find which, if any, perform well and could potentially be utilized to make informed decisions upon.Partially MetThe Random Forest Model with subset logarithmic transformed data was able to produce substantive performance metrics, but may not be repeatable as the cross-validation scores saw a wide range of values.Optimization of the Random Forest regional subset data model, such as through parameter tuning, or implementation of other, similar models are potentials for improvement of this project. XGBoost was attempted; however, it did not show enough validation in performance to continue with testing.
